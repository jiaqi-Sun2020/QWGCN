# import matplotlib.pyplot as plt
# import seaborn as sns
# import numpy as np
# import os
#
# def analyze_model(losses, f1_scores, mses, maes, cm,val_acc_list,args):
#     """
#     ç»¼åˆåˆ†ææ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼š
#     - Loss æ›²çº¿
#     - F1ã€MSEã€MAE æ›²çº¿
#     - æ··æ·†çŸ©é˜µå›¾åƒ
#     - æŒ‡æ ‡ç»Ÿè®¡ä¸è¶‹åŠ¿åˆ†æ
#     """
#
#     os.makedirs(args.save_path, exist_ok=True)
#
#     # ---------- 1. Loss æ›²çº¿ ----------
#     losses = np.array(losses)
#     plt.figure(figsize=(10, 6))
#     plt.plot(range(1, len(losses)+1), losses, marker='o', label='Loss', color='blue')
#
#     window_size = min(10, len(losses)//5) or 1
#     smooth_losses = np.convolve(losses, np.ones(window_size)/window_size, mode='valid')
#     plt.plot(range(window_size, len(losses)+1), smooth_losses, label=f'Smoothed Loss (window={window_size})', color='orange')
#
#     plt.xlabel('Epoch')
#     plt.ylabel('Loss')
#     plt.title(f'{args.model} Training Loss Curve')
#     plt.grid(True)
#     plt.legend()
#     plt.tight_layout()
#     loss_path = os.path.join(args.save_path, 'loss_curve.png')
#     plt.savefig(loss_path)
#     plt.close()
#     print(f"âœ… Loss æ›²çº¿å·²ä¿å­˜è‡³: {loss_path}")
#
#     # ---------- 2. F1 / MSE / MAE æ›²çº¿ ----------
#     if isinstance(f1_scores, list) and len(f1_scores) == len(losses):
#         plt.figure(figsize=(10, 6))
#         plt.plot(f1_scores, label='F1 Score', marker='o')
#         plt.plot(mses, label='MSE', marker='x')
#         plt.plot(maes, label='MAE', marker='s')
#         plt.xlabel('Epoch')
#         plt.title('Model Evaluation Metrics')
#         plt.grid(True)
#         plt.legend()
#         plt.tight_layout()
#         metrics_path = os.path.join(args.save_path, 'metrics_curve.png')
#         plt.savefig(metrics_path)
#         plt.close()
#         print(f"âœ… F1 / MSE / MAE æ›²çº¿å·²ä¿å­˜è‡³: {metrics_path}")
#
#     # ---------- 3. æ··æ·†çŸ©é˜µ ----------
#     plt.figure(figsize=(8, 6))
#     sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
#     plt.xlabel("Predicted")
#     plt.ylabel("True")
#     plt.title("Confusion Matrix")
#     plt.tight_layout()
#     cm_path = os.path.join(args.save_path, 'confusion_matrix_final.png')
#     plt.savefig(cm_path)
#     plt.close()
#     print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: {cm_path}")
#
#     # ---------- 4. æŒ‡æ ‡æ±‡æ€»åˆ†æ ----------
#     print("\nğŸ“Š æŒ‡æ ‡ç»Ÿè®¡ä¸è¶‹åŠ¿åˆ†æ")
#     print(f"- æœ€åˆ Loss: {losses[0]:.4f}")
#     print(f"- æœ€ç»ˆ Loss: {losses[-1]:.4f}")
#     print(f"- æœ€ä½³ Epoch (æœ€ä½ Loss): {np.argmin(losses) + 1}, Loss={np.min(losses):.4f}")
#     print(f"- æœ€ç»ˆ F1 Score: {f1_scores[-1]:.4f}")
#     print(f"- æœ€ç»ˆ MSE: {mses[-1]:.4f}")
#     print(f"- æœ€ç»ˆ MAE: {maes[-1]:.4f}")
#
#     if f1_scores[-1] > 0.8:
#         print("âœ… F1 å¾ˆé«˜ï¼Œæ¨¡å‹åŒºåˆ†æ•ˆæœè‰¯å¥½ã€‚")
#     elif f1_scores[-1] > 0.6:
#         print("âš ï¸ F1 ä¸­ç­‰ï¼Œæ¨¡å‹æœ‰ä¸€å®šæ•ˆæœä½†å¯èƒ½å¯ä¼˜åŒ–ã€‚")
#     else:
#         print("âŒ F1 åä½ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹ç»“æ„æˆ–ç‰¹å¾ã€‚")
#
#     if losses[-1] < losses[0] * 0.5:
#         print("âœ… Loss æ˜æ˜¾ä¸‹é™ï¼Œè®­ç»ƒæ”¶æ•›è‰¯å¥½ã€‚")
#     elif losses[-1] < losses[0] * 0.9:
#         print("âš ï¸ Loss æœ‰ä¸‹é™ï¼Œä½†æ”¶æ•›è¾ƒæ…¢ã€‚")
#     else:
#         print("âŒ Loss å‡ ä¹æœªä¸‹é™ï¼Œå¯èƒ½å­˜åœ¨æ¬ æ‹Ÿåˆã€‚")


# import os
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
#
#
# def analyze_model(trian_losses,val_losses,val_f1_scores, val_mses, val_maes, cm, val_acc_list, args):
#     """
#     ç»¼åˆåˆ†ææ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼š
#     - Loss æ›²çº¿
#     - F1ã€MSEã€MAEã€Accuracy åˆ†åˆ«ç”Ÿæˆç‹¬ç«‹å›¾åƒ
#     - æ··æ·†çŸ©é˜µå›¾åƒ
#     - æŒ‡æ ‡ç»Ÿè®¡ä¸è¶‹åŠ¿åˆ†æ
#     """
#
#     # ç¡®ä¿ä¿å­˜è·¯å¾„å­˜åœ¨
#     os.makedirs(args.save_path, exist_ok=True)
#
#     # æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯
#     losses = np.array(trian_losses) if not isinstance(trian_losses, np.ndarray) else trian_losses
#
#     # å¤„ç†å¯èƒ½ä¸ºç©ºçš„æŒ‡æ ‡åˆ—è¡¨
#     has_f1 = val_f1_scores is not None and len(val_f1_scores) > 0
#     has_mse = val_mses is not None and len(val_mses) > 0
#     has_mae = val_maes is not None and len(val_maes) > 0
#     has_acc = val_acc_list is not None and len(val_acc_list) > 0
#
#     print("ğŸ“Š å¼€å§‹ç”Ÿæˆæ¨¡å‹åˆ†ææŠ¥å‘Š...")
#
#     # ---------- 1. Loss æ›²çº¿ ----------
#     plt.figure(figsize=(10, 6))
#     plt.plot(range(1, len(losses) + 1), losses, marker='o', label='Training Loss', color='blue', linewidth=2)
#
#     # å¹³æ»‘æ›²çº¿
#     if len(losses) > 5:
#         window_size = min(10, len(losses) // 5) or 1
#         if window_size > 1:
#             smooth_losses = np.convolve(losses, np.ones(window_size) / window_size, mode='valid')
#             plt.plot(range(window_size, len(losses) + 1), smooth_losses,
#                      label=f'Smoothed Loss (window={window_size})', color='orange', linewidth=2)
#
#     plt.xlabel('Epoch', fontsize=12)
#     plt.ylabel('Loss', fontsize=12)
#     plt.title(f'{args.model} Training Loss Curve', fontsize=14, fontweight='bold')
#     plt.grid(True, alpha=0.3)
#     plt.legend(fontsize=11)
#     plt.tight_layout()
#     loss_path = os.path.join(args.save_path, 'loss_curve.png')
#     plt.savefig(loss_path, dpi=300, bbox_inches='tight')
#     plt.close()
#     print(f"âœ… Loss æ›²çº¿å·²ä¿å­˜è‡³: {loss_path}")
#
#     # ---------- 2. F1 Score æ›²çº¿ ----------
#     if has_f1:
#         plt.figure(figsize=(10, 6))
#         epochs = range(1, len(val_f1_scores) + 1)
#         plt.plot(epochs, val_f1_scores, marker='o', label='F1 Score', color='green', linewidth=2)
#
#         # æ·»åŠ æœ€ä½³ç‚¹æ ‡è®°
#         best_f1_idx = np.argmax(val_f1_scores)
#         plt.plot(best_f1_idx + 1, val_f1_scores[best_f1_idx], 'ro', markersize=8,
#                  label=f'Best F1: {val_f1_scores[best_f1_idx]:.4f} (Epoch {best_f1_idx + 1})')
#
#         plt.xlabel('Epoch', fontsize=12)
#         plt.ylabel('F1 Score', fontsize=12)
#         plt.title('F1 Score Curve', fontsize=14, fontweight='bold')
#         plt.grid(True, alpha=0.3)
#         plt.legend(fontsize=11)
#         plt.ylim(0, 1.05)  # F1åˆ†æ•°èŒƒå›´0-1
#         plt.tight_layout()
#         f1_path = os.path.join(args.save_path, 'f1_curve.png')
#         plt.savefig(f1_path, dpi=300, bbox_inches='tight')
#         plt.close()
#         print(f"âœ… F1 æ›²çº¿å·²ä¿å­˜è‡³: {f1_path}")
#
#     # ---------- 3. MSE æ›²çº¿ ----------
#     if has_mse:
#         plt.figure(figsize=(10, 6))
#         epochs = range(1, len(val_mses) + 1)
#         plt.plot(epochs, val_mses, marker='x', label='MSE', color='red', linewidth=2)
#
#         # æ·»åŠ æœ€ä½³ç‚¹æ ‡è®°
#         best_mse_idx = np.argmin(val_mses)
#         plt.plot(best_mse_idx + 1, val_mses[best_mse_idx], 'ro', markersize=8,
#                  label=f'Best MSE: {val_mses[best_mse_idx]:.4f} (Epoch {best_mse_idx + 1})')
#
#         plt.xlabel('Epoch', fontsize=12)
#         plt.ylabel('MSE', fontsize=12)
#         plt.title('Mean Squared Error Curve', fontsize=14, fontweight='bold')
#         plt.grid(True, alpha=0.3)
#         plt.legend(fontsize=11)
#         plt.tight_layout()
#         mse_path = os.path.join(args.save_path, 'mse_curve.png')
#         plt.savefig(mse_path, dpi=300, bbox_inches='tight')
#         plt.close()
#         print(f"âœ… MSE æ›²çº¿å·²ä¿å­˜è‡³: {mse_path}")
#
#     # ---------- 4. MAE æ›²çº¿ ----------
#     if has_mae:
#         plt.figure(figsize=(10, 6))
#         epochs = range(1, len(val_maes) + 1)
#         plt.plot(epochs, val_maes, marker='s', label='MAE', color='purple', linewidth=2)
#
#         # æ·»åŠ æœ€ä½³ç‚¹æ ‡è®°
#         best_mae_idx = np.argmin(val_maes)
#         plt.plot(best_mae_idx + 1, val_maes[best_mae_idx], 'ro', markersize=8,
#                  label=f'Best MAE: {val_maes[best_mae_idx]:.4f} (Epoch {best_mae_idx + 1})')
#
#         plt.xlabel('Epoch', fontsize=12)
#         plt.ylabel('MAE', fontsize=12)
#         plt.title('Mean Absolute Error Curve', fontsize=14, fontweight='bold')
#         plt.grid(True, alpha=0.3)
#         plt.legend(fontsize=11)
#         plt.tight_layout()
#         mae_path = os.path.join(args.save_path, 'mae_curve.png')
#         plt.savefig(mae_path, dpi=300, bbox_inches='tight')
#         plt.close()
#         print(f"âœ… MAE æ›²çº¿å·²ä¿å­˜è‡³: {mae_path}")
#
#     # ---------- 5. Accuracy æ›²çº¿ ----------
#     if has_acc:
#         plt.figure(figsize=(10, 6))
#         epochs = range(1, len(val_acc_list) + 1)
#         plt.plot(epochs, val_acc_list, marker='d', label='Validation Accuracy', color='orange', linewidth=2)
#
#         # æ·»åŠ æœ€ä½³ç‚¹æ ‡è®°
#         best_acc_idx = np.argmax(val_acc_list)
#         plt.plot(best_acc_idx + 1, val_acc_list[best_acc_idx], 'ro', markersize=8,
#                  label=f'Best Acc: {val_acc_list[best_acc_idx]:.4f} (Epoch {best_acc_idx + 1})')
#
#         plt.xlabel('Epoch', fontsize=12)
#         plt.ylabel('Accuracy', fontsize=12)
#         plt.title('Validation Accuracy Curve', fontsize=14, fontweight='bold')
#         plt.grid(True, alpha=0.3)
#         plt.legend(fontsize=11)
#         plt.ylim(0, 1.05)  # å‡†ç¡®ç‡èŒƒå›´0-1
#         plt.tight_layout()
#         acc_path = os.path.join(args.save_path, 'accuracy_curve.png')
#         plt.savefig(acc_path, dpi=300, bbox_inches='tight')
#         plt.close()
#         print(f"âœ… Accuracy æ›²çº¿å·²ä¿å­˜è‡³: {acc_path}")
#
#     # ---------- 6. æ··æ·†çŸ©é˜µ ----------
#     if cm is not None:
#         plt.figure(figsize=(8, 6))
#         sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=True,
#                     square=True, linewidths=0.5)
#         plt.xlabel("Predicted", fontsize=12)
#         plt.ylabel("True", fontsize=12)
#         plt.title("Confusion Matrix", fontsize=14, fontweight='bold')
#         plt.tight_layout()
#         cm_path = os.path.join(args.save_path, 'confusion_matrix_final.png')
#         plt.savefig(cm_path, dpi=300, bbox_inches='tight')
#         plt.close()
#         print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: {cm_path}")
#
#     # ---------- 7. æŒ‡æ ‡æ±‡æ€»åˆ†æ ----------
#     print("\n" + "=" * 50)
#     print("ğŸ“Š æŒ‡æ ‡ç»Ÿè®¡ä¸è¶‹åŠ¿åˆ†æ")
#     print("=" * 50)
#
#     # Loss åˆ†æ
#     print(f"ğŸ“‰ Loss åˆ†æ:")
#     print(f"   - åˆå§‹ Loss: {losses[0]:.4f}")
#     print(f"   - æœ€ç»ˆ Loss: {losses[-1]:.4f}")
#     print(f"   - æœ€ä½³ Loss: {np.min(losses):.4f} (Epoch {np.argmin(losses) + 1})")
#     print(f"   - Loss é™å¹…: {((losses[0] - losses[-1]) / losses[0] * 100):.2f}%")
#
#     # F1 åˆ†æ
#     if has_f1:
#         print(f"\nğŸ¯ F1 Score åˆ†æ:")
#         print(f"   - åˆå§‹ F1: {val_f1_scores[0]:.4f}")
#         print(f"   - æœ€ç»ˆ F1: {val_f1_scores[-1]:.4f}")
#         print(f"   - æœ€ä½³ F1: {np.max(val_f1_scores):.4f} (Epoch {np.argmax(val_f1_scores) + 1})")
#
#     # MSE åˆ†æ
#     if has_mse:
#         print(f"\nğŸ“Š MSE åˆ†æ:")
#         print(f"   - åˆå§‹ MSE: {val_mses[0]:.4f}")
#         print(f"   - æœ€ç»ˆ MSE: {val_mses[-1]:.4f}")
#         print(f"   - æœ€ä½³ MSE: {np.min(val_mses):.4f} (Epoch {np.argmin(val_mses) + 1})")
#
#     # MAE åˆ†æ
#     if has_mae:
#         print(f"\nğŸ“ˆ MAE åˆ†æ:")
#         print(f"   - åˆå§‹ MAE: {val_maes[0]:.4f}")
#         print(f"   - æœ€ç»ˆ MAE: {val_maes[-1]:.4f}")
#         print(f"   - æœ€ä½³ MAE: {np.min(val_maes):.4f} (Epoch {np.argmin(val_maes) + 1})")
#
#     # Accuracy åˆ†æ (æ–°å¢)
#     if has_acc:
#         print(f"\nğŸ¯ Accuracy åˆ†æ:")
#         print(f"   - åˆå§‹ Accuracy: {val_acc_list[0]:.4f}")
#         print(f"   - æœ€ç»ˆ Accuracy: {val_acc_list[-1]:.4f}")
#         print(f"   - æœ€ä½³ Accuracy: {np.max(val_acc_list):.4f} (Epoch {np.argmax(val_acc_list) + 1})")
#         print(f"   - å‡†ç¡®ç‡æå‡: {((val_acc_list[-1] - val_acc_list[0]) * 100):.2f}%")
#
#     # ---------- 8. æ¨¡å‹è¯„ä¼°å»ºè®® ----------
#     print("\n" + "=" * 50)
#     print("ğŸ’¡ æ¨¡å‹è¯„ä¼°å»ºè®®")
#     print("=" * 50)
#
#     # F1 Score è¯„ä¼°
#     if has_f1:
#         final_f1 = val_f1_scores[-1]
#         if final_f1 > 0.8:
#             print("âœ… F1 Score å¾ˆé«˜ (>0.8)ï¼Œæ¨¡å‹åŒºåˆ†æ•ˆæœä¼˜ç§€ã€‚")
#         elif final_f1 > 0.6:
#             print("âš ï¸ F1 Score ä¸­ç­‰ (0.6-0.8)ï¼Œæ¨¡å‹æœ‰ä¸€å®šæ•ˆæœä½†å¯ç»§ç»­ä¼˜åŒ–ã€‚")
#         else:
#             print("âŒ F1 Score åä½ (<0.6)ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹ç»“æ„ã€ç‰¹å¾å·¥ç¨‹æˆ–æ•°æ®è´¨é‡ã€‚")
#
#     # Accuracy è¯„ä¼° (æ–°å¢)
#     if has_acc:
#         final_acc = val_acc_list[-1]
#         if final_acc > 0.9:
#             print("âœ… å‡†ç¡®ç‡å¾ˆé«˜ (>90%)ï¼Œæ¨¡å‹æ€§èƒ½ä¼˜ç§€ã€‚")
#         elif final_acc > 0.8:
#             print("âœ… å‡†ç¡®ç‡è‰¯å¥½ (80%-90%)ï¼Œæ¨¡å‹è¡¨ç°ä¸é”™ã€‚")
#         elif final_acc > 0.7:
#             print("âš ï¸ å‡†ç¡®ç‡ä¸­ç­‰ (70%-80%)ï¼Œè¿˜æœ‰ä¼˜åŒ–ç©ºé—´ã€‚")
#         else:
#             print("âŒ å‡†ç¡®ç‡è¾ƒä½ (<70%)ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹é…ç½®å’Œæ•°æ®ã€‚")
#
#     # Loss æ”¶æ•›æ€§è¯„ä¼°
#     loss_reduction = (losses[0] - losses[-1]) / losses[0]
#     if loss_reduction > 0.5:
#         print("âœ… Loss æ˜¾è‘—ä¸‹é™ (>50%)ï¼Œè®­ç»ƒæ”¶æ•›è‰¯å¥½ã€‚")
#     elif loss_reduction > 0.1:
#         print("âš ï¸ Loss æœ‰æ‰€ä¸‹é™ (10%-50%)ï¼Œæ”¶æ•›è¾ƒæ…¢ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡ã€‚")
#     else:
#         print("âŒ Loss å‡ ä¹æœªä¸‹é™ (<10%)ï¼Œå¯èƒ½å­˜åœ¨æ¬ æ‹Ÿåˆæˆ–å­¦ä¹ ç‡é—®é¢˜ã€‚")
#
#     # è¿‡æ‹Ÿåˆæ£€æµ‹ (æ–°å¢)
#     if has_acc and len(val_acc_list) > 10:
#         recent_acc_trend = np.mean(val_acc_list[-5:]) - np.mean(val_acc_list[-10:-5])
#         if recent_acc_trend < -0.02:
#             print("âš ï¸ éªŒè¯å‡†ç¡®ç‡æœ‰ä¸‹é™è¶‹åŠ¿ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆã€‚")
#         elif recent_acc_trend > 0.01:
#             print("âœ… éªŒè¯å‡†ç¡®ç‡æŒç»­æå‡ï¼Œæ¨¡å‹ä»åœ¨å­¦ä¹ ã€‚")
#         else:
#             print("ğŸ“Š éªŒè¯å‡†ç¡®ç‡è¶‹äºç¨³å®šã€‚")
#
#     print("=" * 50)
#     print("ğŸ“ˆ åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
#
#     return {
#         'best_loss': np.min(losses),
#         'best_loss_epoch': np.argmin(losses) + 1,
#         'final_loss': losses[-1],
#         'best_f1': np.max(val_f1_scores) if has_f1 else None,
#         'best_f1_epoch': np.argmax(val_f1_scores) + 1 if has_f1 else None,
#         'final_f1': val_f1_scores[-1] if has_f1 else None,
#         'best_acc': np.max(val_acc_list) if has_acc else None,
#         'best_acc_epoch': np.argmax(val_acc_list) + 1 if has_acc else None,
#         'final_acc': val_acc_list[-1] if has_acc else None,
#         'loss_reduction_rate': loss_reduction
#     }


import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


def analyze_model(trian_losses, val_losses, val_f1_scores, val_mses, val_maes, cm, val_acc_list, args):
    """
    ç»¼åˆåˆ†ææ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼š
    - Loss æ›²çº¿ï¼ˆè®­ç»ƒä¸éªŒè¯åˆ†åˆ«ç»˜åˆ¶ï¼‰
    - F1ã€MSEã€MAEã€Accuracy åˆ†åˆ«ç”Ÿæˆç‹¬ç«‹å›¾åƒ
    - æ··æ·†çŸ©é˜µå›¾åƒ
    - æŒ‡æ ‡ç»Ÿè®¡ä¸è¶‹åŠ¿åˆ†æ
    """
    os.makedirs(args.save_path, exist_ok=True)

    print("ğŸ“Š å¼€å§‹ç”Ÿæˆæ¨¡å‹åˆ†ææŠ¥å‘Š...")

    trian_losses = np.array(trian_losses)
    val_losses = np.array(val_losses) if val_losses is not None else None

    has_f1 = val_f1_scores is not None and len(val_f1_scores) > 0
    has_mse = val_mses is not None and len(val_mses) > 0
    has_mae = val_maes is not None and len(val_maes) > 0
    has_acc = val_acc_list is not None and len(val_acc_list) > 0

    # ---------- 1. Loss æ›²çº¿ ----------
    plt.figure(figsize=(10, 6))
    epochs = np.arange(1, len(trian_losses) + 1)
    plt.plot(epochs, trian_losses, label='Training Loss', color='blue', linewidth=2)

    if val_losses is not None and len(val_losses) > 0:
        val_epochs = np.arange(args.save_freq, args.save_freq * len(val_losses) + 1, args.save_freq)
        plt.plot(val_epochs, val_losses, label='Validation Loss', color='red', linewidth=2, marker='o')

    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.title(f'{args.model} Loss Curve', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.legend(fontsize=11)
    plt.tight_layout()
    loss_path = os.path.join(args.save_path, 'loss_curve.png')
    plt.savefig(loss_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… Loss æ›²çº¿å·²ä¿å­˜è‡³: {loss_path}")

    # ---------- 2. F1 Score ----------
    if has_f1:
        val_epochs = np.arange(args.save_freq, args.save_freq * len(val_f1_scores) + 1, args.save_freq)
        plt.figure(figsize=(10, 6))
        plt.plot(val_epochs, val_f1_scores, marker='o', label='F1 Score', color='green', linewidth=2)
        best_f1_idx = np.argmax(val_f1_scores)
        plt.plot(val_epochs[best_f1_idx], val_f1_scores[best_f1_idx], 'ro', markersize=8,
                 label=f'Best F1: {val_f1_scores[best_f1_idx]:.4f} (Epoch {val_epochs[best_f1_idx]})')
        plt.xlabel('Epoch')
        plt.ylabel('F1 Score')
        plt.title('F1 Score Curve')
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.ylim(0, 1.05)
        plt.tight_layout()
        f1_path = os.path.join(args.save_path, 'f1_curve.png')
        plt.savefig(f1_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… F1 æ›²çº¿å·²ä¿å­˜è‡³: {f1_path}")

    # ---------- 3. MSE ----------
    if has_mse:
        val_epochs = np.arange(args.save_freq, args.save_freq * len(val_mses) + 1, args.save_freq)
        plt.figure(figsize=(10, 6))
        plt.plot(val_epochs, val_mses, marker='x', label='MSE', color='red', linewidth=2)
        best_idx = np.argmin(val_mses)
        plt.plot(val_epochs[best_idx], val_mses[best_idx], 'ro', markersize=8,
                 label=f'Best MSE: {val_mses[best_idx]:.4f} (Epoch {val_epochs[best_idx]})')
        plt.xlabel('Epoch')
        plt.ylabel('MSE')
        plt.title('MSE Curve')
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.tight_layout()
        mse_path = os.path.join(args.save_path, 'mse_curve.png')
        plt.savefig(mse_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… MSE æ›²çº¿å·²ä¿å­˜è‡³: {mse_path}")

    # ---------- 4. MAE ----------
    if has_mae:
        val_epochs = np.arange(args.save_freq, args.save_freq * len(val_maes) + 1, args.save_freq)
        plt.figure(figsize=(10, 6))
        plt.plot(val_epochs, val_maes, marker='s', label='MAE', color='purple', linewidth=2)
        best_idx = np.argmin(val_maes)
        plt.plot(val_epochs[best_idx], val_maes[best_idx], 'ro', markersize=8,
                 label=f'Best MAE: {val_maes[best_idx]:.4f} (Epoch {val_epochs[best_idx]})')
        plt.xlabel('Epoch')
        plt.ylabel('MAE')
        plt.title('MAE Curve')
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.tight_layout()
        mae_path = os.path.join(args.save_path, 'mae_curve.png')
        plt.savefig(mae_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… MAE æ›²çº¿å·²ä¿å­˜è‡³: {mae_path}")

    # ---------- 5. Accuracy ----------
    if has_acc:
        val_epochs = np.arange(args.save_freq, args.save_freq * len(val_acc_list) + 1, args.save_freq)
        plt.figure(figsize=(10, 6))
        plt.plot(val_epochs, val_acc_list, marker='d', label='Validation Accuracy', color='orange', linewidth=2)
        best_idx = np.argmax(val_acc_list)
        plt.plot(val_epochs[best_idx], val_acc_list[best_idx], 'ro', markersize=8,
                 label=f'Best Acc: {val_acc_list[best_idx]:.4f} (Epoch {val_epochs[best_idx]})')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.title('Accuracy Curve')
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.ylim(0, 1.05)
        plt.tight_layout()
        acc_path = os.path.join(args.save_path, 'accuracy_curve.png')
        plt.savefig(acc_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… Accuracy æ›²çº¿å·²ä¿å­˜è‡³: {acc_path}")

    # ---------- 6. æ··æ·†çŸ©é˜µ ----------
    if cm is not None:
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=True,
                    square=True, linewidths=0.5)
        plt.xlabel("Predicted", fontsize=12)
        plt.ylabel("True", fontsize=12)
        plt.title("Confusion Matrix", fontsize=14, fontweight='bold')
        plt.tight_layout()
        cm_path = os.path.join(args.save_path, 'confusion_matrix_final.png')
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: {cm_path}")

    # ---------- 7. æ§åˆ¶å°æ€»ç»“ ----------
    print("\n" + "=" * 50)
    print("ğŸ“Š æŒ‡æ ‡ç»Ÿè®¡ä¸è¶‹åŠ¿åˆ†æ")
    print("=" * 50)


    print(f"ğŸ“‰ Training Loss åˆ†æ:")
    print(f"   - åˆå§‹è®­ç»ƒ Loss: {trian_losses[0]:.4f}")
    print(f"   - æœ€ç»ˆè®­ç»ƒ Loss: {trian_losses[-1]:.4f}")
    best_train_loss = np.min(trian_losses)
    best_train_epoch = np.argmin(trian_losses) + 1
    print(f"   - æœ€ä½³è®­ç»ƒ Loss: {best_train_loss:.4f} (Epoch {best_train_epoch})")
    train_loss_reduction = (trian_losses[0] - trian_losses[-1]) / trian_losses[0]
    print(f"   - Loss é™å¹…: {train_loss_reduction * 100:.2f}%")

    if val_losses is not None and len(val_losses) > 0:
        val_epochs = np.arange(args.save_freq, args.save_freq * len(val_losses) + 1, args.save_freq)
        print(f"\nğŸ“‰ Validation Loss åˆ†æ:")
        print(f"   - åˆå§‹éªŒè¯ Loss: {val_losses[0]:.4f} (Epoch {val_epochs[0]})")
        print(f"   - æœ€ç»ˆéªŒè¯ Loss: {val_losses[-1]:.4f} (Epoch {val_epochs[-1]})")
        best_val_loss = np.min(val_losses)
        best_val_epoch = val_epochs[np.argmin(val_losses)]
        print(f"   - æœ€ä½³éªŒè¯ Loss: {best_val_loss:.4f} (Epoch {best_val_epoch})")
        val_loss_reduction = (val_losses[0] - val_losses[-1]) / val_losses[0]
        print(f"   - Loss é™å¹…: {val_loss_reduction * 100:.2f}%")



    if has_f1:
        print(f"\nğŸ¯ F1 Score åˆ†æ:")
        print(f"   - åˆå§‹ F1: {val_f1_scores[0]:.4f}")
        print(f"   - æœ€ç»ˆ F1: {val_f1_scores[-1]:.4f}")
        print(f"   - æœ€ä½³ F1: {np.max(val_f1_scores):.4f} (Epoch {np.argmax(val_f1_scores) + 1})")

    # MSE åˆ†æ
    if has_mse:
        print(f"\nğŸ“Š MSE åˆ†æ:")
        print(f"   - åˆå§‹ MSE: {val_mses[0]:.4f}")
        print(f"   - æœ€ç»ˆ MSE: {val_mses[-1]:.4f}")
        print(f"   - æœ€ä½³ MSE: {np.min(val_mses):.4f} (Epoch {np.argmin(val_mses) + 1})")

    # MAE åˆ†æ
    if has_mae:
        print(f"\nğŸ“ˆ MAE åˆ†æ:")
        print(f"   - åˆå§‹ MAE: {val_maes[0]:.4f}")
        print(f"   - æœ€ç»ˆ MAE: {val_maes[-1]:.4f}")
        print(f"   - æœ€ä½³ MAE: {np.min(val_maes):.4f} (Epoch {np.argmin(val_maes) + 1})")

    # Accuracy åˆ†æ (æ–°å¢)
    if has_acc:
        print(f"\nğŸ¯ Accuracy åˆ†æ:")
        print(f"   - åˆå§‹ Accuracy: {val_acc_list[0]:.4f}")
        print(f"   - æœ€ç»ˆ Accuracy: {val_acc_list[-1]:.4f}")
        print(f"   - æœ€ä½³ Accuracy: {np.max(val_acc_list):.4f} (Epoch {np.argmax(val_acc_list) + 1})")
        print(f"   - å‡†ç¡®ç‡æå‡: {((val_acc_list[-1] - val_acc_list[0]) * 100):.2f}%")

    # ---------- 8. æ¨¡å‹è¯„ä¼°å»ºè®® ----------
    print("\n" + "=" * 50)
    print("ğŸ’¡ æ¨¡å‹è¯„ä¼°å»ºè®®")
    print("=" * 50)

    # F1 Score è¯„ä¼°
    if has_f1:
        final_f1 = val_f1_scores[-1]
        if final_f1 > 0.8:
            print("âœ… F1 Score å¾ˆé«˜ (>0.8)ï¼Œæ¨¡å‹åŒºåˆ†æ•ˆæœä¼˜ç§€ã€‚")
        elif final_f1 > 0.6:
            print("âš ï¸ F1 Score ä¸­ç­‰ (0.6-0.8)ï¼Œæ¨¡å‹æœ‰ä¸€å®šæ•ˆæœä½†å¯ç»§ç»­ä¼˜åŒ–ã€‚")
        else:
            print("âŒ F1 Score åä½ (<0.6)ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹ç»“æ„ã€ç‰¹å¾å·¥ç¨‹æˆ–æ•°æ®è´¨é‡ã€‚")

    # Accuracy è¯„ä¼° (æ–°å¢)
    if has_acc:
        final_acc = val_acc_list[-1]
        if final_acc > 0.9:
            print("âœ… å‡†ç¡®ç‡å¾ˆé«˜ (>90%)ï¼Œæ¨¡å‹æ€§èƒ½ä¼˜ç§€ã€‚")
        elif final_acc > 0.8:
            print("âœ… å‡†ç¡®ç‡è‰¯å¥½ (80%-90%)ï¼Œæ¨¡å‹è¡¨ç°ä¸é”™ã€‚")
        elif final_acc > 0.7:
            print("âš ï¸ å‡†ç¡®ç‡ä¸­ç­‰ (70%-80%)ï¼Œè¿˜æœ‰ä¼˜åŒ–ç©ºé—´ã€‚")
        else:
            print("âŒ å‡†ç¡®ç‡è¾ƒä½ (<70%)ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹é…ç½®å’Œæ•°æ®ã€‚")

    # Loss æ”¶æ•›æ€§è¯„ä¼°
    loss_reduction = (trian_losses[0] - trian_losses[-1]) / trian_losses[0]
    if loss_reduction > 0.5:
        print("âœ… Loss æ˜¾è‘—ä¸‹é™ (>50%)ï¼Œè®­ç»ƒæ”¶æ•›è‰¯å¥½ã€‚")
    elif loss_reduction > 0.1:
        print("âš ï¸ Loss æœ‰æ‰€ä¸‹é™ (10%-50%)ï¼Œæ”¶æ•›è¾ƒæ…¢ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡ã€‚")
    else:
        print("âŒ Loss å‡ ä¹æœªä¸‹é™ (<10%)ï¼Œå¯èƒ½å­˜åœ¨æ¬ æ‹Ÿåˆæˆ–å­¦ä¹ ç‡é—®é¢˜ã€‚")

    # è¿‡æ‹Ÿåˆæ£€æµ‹ (æ–°å¢)
    if has_acc and len(val_acc_list) > 10:
        recent_acc_trend = np.mean(val_acc_list[-5:]) - np.mean(val_acc_list[-10:-5])
        if recent_acc_trend < -0.02:
            print("âš ï¸ éªŒè¯å‡†ç¡®ç‡æœ‰ä¸‹é™è¶‹åŠ¿ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆã€‚")
        elif recent_acc_trend > 0.01:
            print("âœ… éªŒè¯å‡†ç¡®ç‡æŒç»­æå‡ï¼Œæ¨¡å‹ä»åœ¨å­¦ä¹ ã€‚")
        else:
            print("ğŸ“Š éªŒè¯å‡†ç¡®ç‡è¶‹äºç¨³å®šã€‚")

    print("=" * 50)
    print("ğŸ“ˆ åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")








    return {
        'best_loss': np.min(trian_losses),
        'best_loss_epoch': np.argmin(trian_losses) + 1,
        'final_loss': trian_losses[-1],
        'best_f1': np.max(val_f1_scores) if has_f1 else None,
        'best_f1_epoch': val_epochs[np.argmax(val_f1_scores)] if has_f1 else None,
        'final_f1': val_f1_scores[-1] if has_f1 else None,
        'best_acc': np.max(val_acc_list) if has_acc else None,
        'best_acc_epoch': val_epochs[np.argmax(val_acc_list)] if has_acc else None,
        'final_acc': val_acc_list[-1] if has_acc else None,
    }
