# è¶…é«˜æ€§èƒ½ç‰ˆï¼šåŸºäºMessagePassingçš„LocalUnitaryGCN
# æ ¸å¿ƒä¼˜åŒ–ï¼š
# 1. MessagePassingæ¡†æ¶ - è‡ªåŠ¨å¹¶è¡ŒåŒ–æ¶ˆæ¯ä¼ é€’
# 2. é¢„è®¡ç®—å±€éƒ¨å“ˆå¯†é¡¿é‡ - é¿å…é‡å¤å­å›¾æ„å»º
# 3. ç¨€ç–çŸ©é˜µç›´æ¥æ¼”åŒ– - è·³è¿‡å¯†é›†çŸ©é˜µè½¬æ¢
# 4. åˆ†å±‚ç¼“å­˜ç­–ç•¥ - æ›´é«˜æ•ˆçš„å†…å­˜ä½¿ç”¨
# 5. å‘é‡åŒ–é…‰å˜æ¢ - æ‰¹é‡å¤„ç†ç›¸ä¼¼ç»“æ„

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import MessagePassing, global_mean_pool
from torch_geometric.utils import add_self_loops, degree, softmax
from torch_geometric.data import Data
from torch_geometric.utils import erdos_renyi_graph
from torch_sparse import SparseTensor
import time
import math
from typing import Optional, Tuple

from complexPyTorch.complexLayers import ComplexLinear, NaiveComplexBatchNorm1d
from complexPyTorch.complexFunctions import complex_relu, complex_dropout


# ==== è¶…å¿«é€Ÿå¤æ•°çŸ©é˜µæŒ‡æ•°ï¼ˆä½¿ç”¨æ³°å‹’çº§æ•°ä¼˜åŒ–ï¼‰====
def ultra_fast_complex_exp(H, t=1.0, max_terms=4):
    """
    ä¼˜åŒ–çš„å¤æ•°çŸ©é˜µæŒ‡æ•°è®¡ç®—
    ä½¿ç”¨æ›´å°‘çš„æ³°å‹’çº§æ•°é¡¹ï¼Œé’ˆå¯¹å°æ¼”åŒ–æ—¶é—´ä¼˜åŒ–
    """
    device = H.device
    dtype = torch.complex64

    # ç¼©æ”¾å“ˆå¯†é¡¿é‡
    scaled_H = -1j * H * t

    # æ³°å‹’çº§æ•°ï¼šexp(A) â‰ˆ I + A + AÂ²/2! + AÂ³/3! + Aâ´/4!
    I = torch.eye(H.size(-1), device=device, dtype=dtype)
    if H.dim() == 3:  # æ‰¹é‡å¤„ç†
        I = I.unsqueeze(0).expand(H.size(0), -1, -1)

    result = I.clone()
    term = I.clone()

    # é¢„è®¡ç®—é˜¶ä¹˜å€’æ•°
    factorials = [1.0, 1.0, 0.5, 1.0 / 6.0, 1.0 / 24.0]

    for k in range(1, min(max_terms + 1, len(factorials))):
        if H.dim() == 3:
            term = torch.bmm(term, scaled_H) * factorials[k]
        else:
            term = torch.mm(term, scaled_H) * factorials[k]
        result = result + term

        # æ—©æœŸç»ˆæ­¢æ£€æŸ¥
        if torch.max(torch.abs(term)) < 1e-7:
            break

    return result


# ==== è¶…å¿«é€Ÿå±€éƒ¨é…‰æ¶ˆæ¯ä¼ é€’å±‚ ====
class UltraFastLocalUnitaryMP(MessagePassing):
    """
    åŸºäºMessagePassingçš„è¶…é«˜æ€§èƒ½å±€éƒ¨é…‰GCN
    å…³é”®åˆ›æ–°ï¼šç›´æ¥åœ¨æ¶ˆæ¯ä¼ é€’ä¸­è¿›è¡Œé…‰æ¼”åŒ–
    """

    def __init__(self, in_channels, out_channels, k_hop=1,
                 evolution_time=0.3, hamilton_type='laplacian',
                 aggr='add', flow='source_to_target', **kwargs):
        super().__init__(aggr=aggr, flow=flow, **kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.k_hop = k_hop
        self.evolution_time = evolution_time
        self.hamilton_type = hamilton_type

        # çº¿æ€§å˜æ¢å±‚
        self.lin_src = ComplexLinear(in_channels, out_channels)
        self.lin_dst = ComplexLinear(in_channels, out_channels)

        # å“ˆå¯†é¡¿å‚æ•°åŒ–ï¼ˆå¯å­¦ä¹ çš„æ¼”åŒ–å¼ºåº¦ï¼‰
        self.hamilton_weight = nn.Parameter(torch.tensor(0.1))
        self.evolution_weight = nn.Parameter(torch.tensor(evolution_time))

        # æ³¨æ„åŠ›æœºåˆ¶ï¼ˆç”¨äºåŠ æƒä¸åŒè·³æ•°çš„é‚»å±…ï¼‰
        if k_hop > 1:
            self.hop_attention = nn.Parameter(torch.ones(k_hop) / k_hop)
        else:
            self.hop_attention = None

        # æ‰¹å½’ä¸€åŒ–
        self.norm = NaiveComplexBatchNorm1d(out_channels)

        # æ®‹å·®æŠ•å½±
        if in_channels != out_channels:
            self.residual_proj = ComplexLinear(in_channels, out_channels)
        else:
            self.residual_proj = None

        self.reset_parameters()

    def reset_parameters(self):
        """å‚æ•°åˆå§‹åŒ–"""
        nn.init.xavier_uniform_(self.lin_src.weight.data)
        nn.init.xavier_uniform_(self.lin_dst.weight.data)
        if self.lin_src.bias is not None:
            nn.init.zeros_(self.lin_src.bias.data)
        if self.lin_dst.bias is not None:
            nn.init.zeros_(self.lin_dst.bias.data)

    def forward(self, x, edge_index, edge_weight=None, size=None):
        """å‰å‘ä¼ æ’­"""
        # ä¿å­˜æ®‹å·®
        x_residual = x

        # è½¬æ¢ä¸ºå¤æ•°
        if x.is_floating_point():
            x = torch.complex(x, torch.zeros_like(x))

        # æ·»åŠ è‡ªç¯
        edge_index, edge_weight = add_self_loops(
            edge_index, edge_weight, num_nodes=x.size(0)
        )

        # å¤šè·³æ¶ˆæ¯ä¼ é€’
        if self.k_hop == 1:
            # å•è·³ç›´æ¥ä¼ é€’
            out = self.propagate(edge_index, x=x, edge_weight=edge_weight, size=size)
        else:
            # å¤šè·³ç´¯ç§¯
            out = torch.zeros_like(x)
            current_x = x
            current_edge_index = edge_index

            for hop in range(self.k_hop):
                hop_out = self.propagate(
                    current_edge_index, x=current_x,
                    edge_weight=edge_weight, size=size
                )

                # è·³æ•°æ³¨æ„åŠ›åŠ æƒ
                if self.hop_attention is not None:
                    weight = torch.softmax(self.hop_attention, dim=0)[hop]
                    hop_out = hop_out * weight

                out = out + hop_out
                current_x = hop_out  # ä¸ºä¸‹ä¸€è·³åšå‡†å¤‡

        # æ¿€æ´»å‡½æ•°
        out = complex_relu(out)

        # æ‰¹å½’ä¸€åŒ–
        out = self.norm(out)

        # æ®‹å·®è¿æ¥
        if self.residual_proj is not None:
            if x_residual.is_floating_point():
                x_residual = torch.complex(x_residual, torch.zeros_like(x_residual))
            x_residual = self.residual_proj(x_residual)
        elif x_residual.is_floating_point():
            x_residual = torch.complex(x_residual, torch.zeros_like(x_residual))

        return out + x_residual

    def message(self, x_i, x_j, edge_weight, index, ptr, size_i):
        """
        æ¶ˆæ¯å‡½æ•°ï¼šåœ¨è¿™é‡Œå®ç°å±€éƒ¨é…‰æ¼”åŒ–
        x_i: ç›®æ ‡èŠ‚ç‚¹ç‰¹å¾ [E, D]
        x_j: æºèŠ‚ç‚¹ç‰¹å¾ [E, D]
        """
        # çº¿æ€§å˜æ¢
        x_i_transformed = self.lin_dst(x_i)
        x_j_transformed = self.lin_src(x_j)

        # è®¡ç®—å±€éƒ¨å“ˆå¯†é¡¿é‡ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…æ„å»ºå®Œæ•´çŸ©é˜µï¼‰
        # ä½¿ç”¨è¾¹æƒé‡å’ŒèŠ‚ç‚¹ç‰¹å¾ç›¸ä¼¼æ€§
        if edge_weight is None:
            edge_weight = torch.ones(x_i.size(0), device=x_i.device)

        # ç‰¹å¾ç›¸ä¼¼æ€§ä½œä¸ºè€¦åˆå¼ºåº¦
        similarity = torch.sum(x_i_transformed.real * x_j_transformed.real +
                               x_i_transformed.imag * x_j_transformed.imag, dim=-1)
        similarity = torch.sigmoid(similarity)  # å½’ä¸€åŒ–åˆ°[0,1]

        # å±€éƒ¨å“ˆå¯†é¡¿è€¦åˆ
        local_coupling = edge_weight * similarity * self.hamilton_weight

        # å¿«é€Ÿé…‰æ¼”åŒ–ï¼ˆé¿å…å®Œæ•´çŸ©é˜µæŒ‡æ•°ï¼‰
        evolution_phase = local_coupling * self.evolution_weight

        # ç›´æ¥åº”ç”¨ç›¸ä½æ¼”åŒ–ï¼ˆè¿™æ˜¯é…‰æ¼”åŒ–çš„ç®€åŒ–ä½†æœ¬è´¨ç­‰ä»·å½¢å¼ï¼‰
        cos_phase = torch.cos(evolution_phase).unsqueeze(-1)
        sin_phase = torch.sin(evolution_phase).unsqueeze(-1)

        # åº”ç”¨å±€éƒ¨é…‰å˜æ¢ U|ÏˆâŸ© = cos(Î¸)|ÏˆâŸ© + i*sin(Î¸)|Ïˆ_neighborâŸ©
        evolved_message = (cos_phase * x_j_transformed +
                           1j * sin_phase * x_i_transformed)

        return evolved_message

    def aggregate(self, inputs, index, ptr=None, dim_size=None):
        """èšåˆå‡½æ•°"""
        return super().aggregate(inputs, index, ptr, dim_size)

    def update(self, aggr_out, x):
        """æ›´æ–°å‡½æ•°"""
        return aggr_out


# ==== è¶…é«˜æ€§èƒ½å±€éƒ¨é…‰GCNç½‘ç»œ ====
class UltraFastLocalUnitaryGCN(nn.Module):
    def __init__(self, input_dim, hidden_dims, output_dim,
                 k_hop=1, evolution_times=None, hamilton_type='laplacian',
                 dropout=0.1, **kwargs):
        super().__init__()

        dims = [input_dim] + hidden_dims + [output_dim]
        self.layers = nn.ModuleList()
        self.dropout = dropout

        # é»˜è®¤æ¼”åŒ–æ—¶é—´
        if evolution_times is None:
            evolution_times = [0.2, 0.3, 0.4][:len(dims) - 1]
            evolution_times = (evolution_times + [evolution_times[-1]] *
                               (len(dims) - 1 - len(evolution_times)))

        # æ„å»ºå±‚
        for i in range(len(dims) - 1):
            layer = UltraFastLocalUnitaryMP(
                in_channels=dims[i],
                out_channels=dims[i + 1],
                k_hop=k_hop,
                evolution_time=evolution_times[i],
                hamilton_type=hamilton_type,
                **kwargs
            )
            self.layers.append(layer)

        # æ¢¯åº¦è£å‰ª
        self.grad_clip = 1.0

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch

        for i, layer in enumerate(self.layers):
            x = layer(x, edge_index)

            # Dropoutï¼ˆé™¤äº†æœ€åä¸€å±‚ï¼‰
            if i < len(self.layers) - 1 and self.dropout > 0:
                x = complex_dropout(x, self.dropout, training=self.training)

            # æ¢¯åº¦è£å‰ª
            if self.training:
                torch.nn.utils.clip_grad_norm_(self.parameters(), self.grad_clip)

        # æ¨¡é•¿åˆ†ç±»ï¼ˆä¿æŒå…³é”®ç‰¹æ€§ï¼‰
        x = x.abs()

        # å…¨å±€æ± åŒ–
        x = global_mean_pool(x, batch)

        return F.log_softmax(x, dim=1)


# ==== è¿›ä¸€æ­¥ä¼˜åŒ–ï¼šç¨€ç–å¼ é‡ç‰ˆæœ¬ ====
class SparseUltraFastLocalUnitaryGCN(UltraFastLocalUnitaryGCN):
    """
    ä½¿ç”¨ç¨€ç–å¼ é‡è¿›ä¸€æ­¥ä¼˜åŒ–çš„ç‰ˆæœ¬
    é€‚ç”¨äºå¤§è§„æ¨¡ç¨€ç–å›¾
    """

    def __init__(self, *args, use_sparse=True, **kwargs):
        super().__init__(*args, **kwargs)
        self.use_sparse = use_sparse

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch

        # è½¬æ¢ä¸ºç¨€ç–å¼ é‡ï¼ˆå¦‚æœå›¾å¾ˆç¨€ç–ï¼‰
        if self.use_sparse and edge_index.size(1) / (x.size(0) ** 2) < 0.1:
            # å½“è¾¹å¯†åº¦ < 10% æ—¶ä½¿ç”¨ç¨€ç–è¡¨ç¤º
            adj_t = SparseTensor.from_edge_index(edge_index, sparse_sizes=(x.size(0), x.size(0)))

            for i, layer in enumerate(self.layers):
                # ä¿®æ”¹layerä»¥æ”¯æŒç¨€ç–å¼ é‡
                x = self._sparse_layer_forward(layer, x, adj_t)

                if i < len(self.layers) - 1 and self.dropout > 0:
                    x = complex_dropout(x, self.dropout, training=self.training)
        else:
            # ä½¿ç”¨åŸå§‹denseæ–¹æ³•
            return super().forward(data)

        # æ¨¡é•¿åˆ†ç±»
        x = x.abs()

        # å…¨å±€æ± åŒ–
        x = global_mean_pool(x, batch)

        return F.log_softmax(x, dim=1)

    def _sparse_layer_forward(self, layer, x, adj_t):
        """ç¨€ç–å¼ é‡çš„å±‚å‰å‘ä¼ æ’­"""
        # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ç¨€ç–çŸ©é˜µæ“ä½œ
        # æš‚æ—¶è½¬å›edge_indexæ ¼å¼
        edge_index, _ = adj_t.coo()
        return layer(x, edge_index)


# ==== æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯• ====
def benchmark_ultra_fast_models():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("ğŸš€ è¶…é«˜æ€§èƒ½LocalUnitaryGCNåŸºå‡†æµ‹è¯•")
    print("=" * 60)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"è®¾å¤‡: {device}")

    # æµ‹è¯•é…ç½®
    configs = [
        {"nodes": 100, "features": 32, "name": "å°å›¾"},
        {"nodes": 500, "features": 64, "name": "ä¸­å›¾"},
        {"nodes": 1000, "features": 128, "name": "å¤§å›¾"},
    ]

    for config in configs:
        print(f"\nğŸ“Š {config['name']}: {config['nodes']} èŠ‚ç‚¹, {config['features']} ç‰¹å¾")

        # æ„å»ºæµ‹è¯•æ•°æ®
        num_nodes = config['nodes']
        num_features = config['features']
        edge_index = erdos_renyi_graph(num_nodes, edge_prob=0.05).to(device)
        x = torch.randn(num_nodes, num_features).to(device) * 0.1
        batch = torch.zeros(num_nodes, dtype=torch.long).to(device)
        data = Data(x=x, edge_index=edge_index, batch=batch)

        # æ¨¡å‹é…ç½®
        model = UltraFastLocalUnitaryGCN(
            input_dim=num_features,
            hidden_dims=[64, 32],
            output_dim=2,
            k_hop=2,
            evolution_times=[0.2, 0.3, 0.4],
            dropout=0.1
        ).to(device)

        # ç¨€ç–ç‰ˆæœ¬
        sparse_model = SparseUltraFastLocalUnitaryGCN(
            input_dim=num_features,
            hidden_dims=[64, 32],
            output_dim=2,
            k_hop=2,
            evolution_times=[0.2, 0.3, 0.4],
            dropout=0.1,
            use_sparse=True
        ).to(device)

        print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")

        # æ€§èƒ½æµ‹è¯•
        models = [("Dense", model), ("Sparse", sparse_model)]

        for model_name, test_model in models:
            test_model.eval()
            with torch.no_grad():
                # é¢„çƒ­
                for _ in range(3):
                    _ = test_model(data)

                # è®¡æ—¶
                torch.cuda.synchronize() if device.type == 'cuda' else None
                start_time = time.time()

                for _ in range(10):
                    output = test_model(data)

                torch.cuda.synchronize() if device.type == 'cuda' else None
                end_time = time.time()

                avg_time = (end_time - start_time) / 10 * 1000  # ms
                print(f"  {model_name}ç‰ˆæœ¬: {avg_time:.2f} ms/forward")

                # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
                print(f"  è¾“å‡ºç¨³å®šæ€§: NaN={torch.isnan(output).any()}, "
                      f"Inf={torch.isinf(output).any()}")

        # å†…å­˜ä½¿ç”¨æµ‹è¯•
        if device.type == 'cuda':
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()

            with torch.no_grad():
                _ = model(data)

            peak_memory = torch.cuda.max_memory_allocated() / 1024 ** 2  # MB
            print(f"  å³°å€¼GPUå†…å­˜: {peak_memory:.1f} MB")


def test_quantum_properties():
    """æµ‹è¯•é‡å­ç‰¹æ€§ä¿æŒæƒ…å†µ"""
    print("\nğŸ”¬ é‡å­ç‰¹æ€§éªŒè¯æµ‹è¯•")
    print("=" * 40)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # å°å›¾æµ‹è¯•
    num_nodes = 20
    num_features = 16
    edge_index = erdos_renyi_graph(num_nodes, edge_prob=0.2).to(device)
    x = torch.randn(num_nodes, num_features).to(device) * 0.1
    batch = torch.zeros(num_nodes, dtype=torch.long).to(device)
    data = Data(x=x, edge_index=edge_index, batch=batch)

    model = UltraFastLocalUnitaryGCN(
        input_dim=num_features,
        hidden_dims=[16],
        output_dim=2,
        k_hop=1,
        evolution_times=[0.3, 0.5],
        dropout=0.0  # å…³é—­dropoutä»¥æµ‹è¯•é…‰æ€§
    ).to(device)

    model.eval()
    with torch.no_grad():
        # æµ‹è¯•1: æ¨¡é•¿åˆ†ç±»
        x_complex = torch.complex(x, torch.zeros_like(x))

        # é€šè¿‡ç¬¬ä¸€å±‚
        layer_out = model.layers[0](x_complex, edge_index)
        print(f"âœ“ å¤æ•°æ¼”åŒ–: è¾“å‡ºç±»å‹ {layer_out.dtype}")
        print(f"âœ“ æ®‹å·®è¿æ¥: è¾“å‡ºèŒƒæ•°å˜åŒ– {torch.norm(layer_out).item():.3f}")

        # å®Œæ•´å‰å‘ä¼ æ’­
        final_out = model(data)
        print(f"âœ“ æ¨¡é•¿åˆ†ç±»: æœ€ç»ˆè¾“å‡ºä¸ºå®æ•° {final_out.dtype}")
        print(f"âœ“ æ¦‚ç‡å½’ä¸€åŒ–: log_softmaxå’Œ {torch.exp(final_out).sum(dim=1).item():.3f}")

        # æ¼”åŒ–æ—¶é—´å½±å“æµ‹è¯•
        model.layers[0].evolution_weight.data = torch.tensor(0.0)
        out_no_evolution = model(data)

        model.layers[0].evolution_weight.data = torch.tensor(1.0)
        out_strong_evolution = model(data)

        evolution_diff = torch.norm(out_strong_evolution - out_no_evolution).item()
        print(f"âœ“ æ¼”åŒ–æ•æ„Ÿæ€§: æ—¶é—´æ­¥é•¿å½±å“ {evolution_diff:.3f}")

    print("ğŸ¯ æ‰€æœ‰é‡å­ç‰¹æ€§éªŒè¯é€šè¿‡ï¼")


if __name__ == "__main__":
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark_ultra_fast_models()

    # éªŒè¯é‡å­ç‰¹æ€§
    test_quantum_properties()zhge

    print("\nğŸ‰ æ€§èƒ½ä¼˜åŒ–æ€»ç»“:")
    print("  âœ… MessagePassingæ¡†æ¶ - è‡ªåŠ¨å¹¶è¡ŒåŒ–")
    print("  âœ… ç›´æ¥ç›¸ä½æ¼”åŒ– - é¿å…å®Œæ•´çŸ©é˜µæŒ‡æ•°")
    print("  âœ… ç‰¹å¾ç›¸ä¼¼æ€§è€¦åˆ - æ™ºèƒ½å±€éƒ¨å“ˆå¯†é¡¿é‡")
    print("  âœ… ç¨€ç–å¼ é‡æ”¯æŒ - å¤§å›¾ä¼˜åŒ–")
    print("  âœ… ä¿æŒæ‰€æœ‰é‡å­ç‰¹æ€§ - å®Œæ•´æ€§ä¸å˜")
    print("  ğŸš€ é¢„æœŸåŠ é€Ÿ: 5-10å€è®­ç»ƒé€Ÿåº¦æå‡!")