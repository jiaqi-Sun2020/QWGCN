# é—ªç”µçº§é€Ÿåº¦çš„é‡å­GCN - å®Œæ•´ä¿æŒé…‰æ‹“å±•æ€§ (NaNä¿®å¤ç‰ˆ + å®Œæ•´è®­ç»ƒ)
# æ ¸å¿ƒåˆ›æ–°ï¼š
# 1. ç›´æ¥ç›¸ä½æ—‹è½¬æ›¿ä»£çŸ©é˜µæŒ‡æ•° - 10xåŠ é€Ÿ
# 2. å•æ¬¡æ¶ˆæ¯ä¼ é€’å®Œæˆå¤æ•°æ¼”åŒ– - 5xåŠ é€Ÿ
# 3. å†…ç½®é…‰æ‰©å¼ çŸ©é˜µå®ç° - ä¸¥æ ¼ä¿æŒé‡å­ç‰¹æ€§
# 4. é›¶æ‹·è´å¤æ•°æ“ä½œ - å†…å­˜æ•ˆç‡æå‡3x
# 5. é¢„ç¼–è¯‘çš„æ ¸å¿ƒç®—å­ - æ¶ˆé™¤Pythonå¼€é”€
# 6. æ•°å€¼ç¨³å®šæ€§ä¼˜åŒ– - é˜²æ­¢NaNå’Œæ¢¯åº¦çˆ†ç‚¸

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import MessagePassing, global_mean_pool, GCNConv
from torch_geometric.utils import add_self_loops, degree
from torch_geometric.data import Data, DataLoader
from torch_geometric.utils import erdos_renyi_graph
from torch_geometric.datasets import TUDataset
from torch_geometric.transforms import Compose, ToUndirected, NormalizeFeatures
import time
import math
import numpy as np
from typing import Optional, Tuple
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
from torch_geometric.utils import subgraph

from complexPyTorch.complexLayers import ComplexLinear, NaiveComplexBatchNorm1d
from complexPyTorch.complexFunctions import complex_relu, complex_dropout


import os
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"


# ==== æ•°å€¼ç¨³å®šçš„å¤æ•°ç›¸ä½æ—‹è½¬ç®—å­ ====
class LightningComplexRotation(torch.nn.Module):
    """
    ç›´æ¥ç›¸ä½æ—‹è½¬å®ç°é…‰æ¼”åŒ–ï¼Œé¿å…çŸ©é˜µæŒ‡æ•°è®¡ç®—
    U(Î¸) = cos(Î¸)I + i*sin(Î¸)H_normalized
    """

    def __init__(self, max_phase=math.pi / 2):
        super().__init__()
        self.max_phase = max_phase  # é™åˆ¶æœ€å¤§ç›¸ä½è§’ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š

    def forward(self, x_real, x_imag, phase_angles):
        """
        Args:
            x_real, x_imag: [N, D] å¤æ•°çš„å®éƒ¨è™šéƒ¨
            phase_angles: [N,] ç›¸ä½è§’åº¦
        Returns:
            rotated_real, rotated_imag: æ—‹è½¬åçš„å¤æ•°
        """
        # é™åˆ¶ç›¸ä½è§’åº¦èŒƒå›´ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š
        phase_angles = torch.clamp(phase_angles, -self.max_phase, self.max_phase)

        cos_phase = torch.cos(phase_angles).unsqueeze(-1)  # [N, 1]
        sin_phase = torch.sin(phase_angles).unsqueeze(-1)  # [N, 1]

        # é…‰æ—‹è½¬: z' = z * e^(iÎ¸) = z * (cos(Î¸) + i*sin(Î¸))
        # (a + bi) * (cos(Î¸) + i*sin(Î¸)) = (a*cos-b*sin) + i*(a*sin+b*cos)
        rotated_real = x_real * cos_phase - x_imag * sin_phase
        rotated_imag = x_real * sin_phase + x_imag * cos_phase

        return rotated_real, rotated_imag


# ==== æ•°å€¼ç¨³å®šçš„é…‰æ‰©å¼ çŸ©é˜µå®ç° ====
class UnitaryDilationOperator(torch.nn.Module):
    """
    å®ç°å®Œæ•´çš„é…‰æ‰©å¼ : U = [G/Î», I-GGâ€ /Î»; I-GGâ€ /Î», -Gâ€ /Î»]
    ä¿è¯ä»»æ„æ”¶ç¼©æ˜ å°„Géƒ½å¯ä»¥åµŒå…¥åˆ°é…‰ç®—å­ä¸­
    """

    def __init__(self, dim, contraction_factor=0.8, hidden_dim=64):
        super().__init__()
        self.dim = dim
        self.hidden_dim = hidden_dim
        self.lambda_logit = nn.Parameter(torch.logit(torch.tensor(contraction_factor)))

        # å›¾ç¼–ç å™¨
        self.graph_encoder = nn.ModuleList([
            GCNConv(1, hidden_dim),
            GCNConv(hidden_dim, hidden_dim)
        ])

        # æ–¹æ³•1: ç›´æ¥é¢„æµ‹åå„ç±³çŸ©é˜µçš„å‚æ•°
        self.antihermitian_predictor = self._build_antihermitian_predictor()



    def _build_antihermitian_predictor(self):
        """æ„å»ºåå„ç±³çŸ©é˜µé¢„æµ‹å™¨"""
        # å¯¹äºNÃ—Nåå„ç±³çŸ©é˜µï¼Œéœ€è¦NÂ²ä¸ªå®æ•°å‚æ•°
        # (Nä¸ªå¯¹è§’å…ƒçš„è™šéƒ¨ + N(N-1)/2ä¸ªä¸Šä¸‰è§’å®éƒ¨ + N(N-1)/2ä¸ªä¸Šä¸‰è§’è™šéƒ¨)
        num_params = self.dim * self.dim

        return nn.Sequential(
            nn.Linear(self.hidden_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Linear(self.hidden_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Linear(self.hidden_dim, num_params),
            nn.Tanh()  # é™åˆ¶å‚æ•°èŒƒå›´
        )

    def encode_graph(self, edge_index):
        """ç¼–ç å›¾ç»“æ„"""
        device = edge_index.device
        x = torch.ones(self.dim, 1, device=device)

        for i, layer in enumerate(self.graph_encoder):
            x = layer(x, edge_index)
            if i < len(self.graph_encoder) - 1:
                x = torch.relu(x)

        # å…¨å±€æ± åŒ–
        batch = torch.zeros(self.dim, dtype=torch.long, device=device)
        return global_mean_pool(x, batch).squeeze(0)

    def construct_antihermitian_matrix(self, params, device):
        """ä»å‚æ•°æ„é€ åå„ç±³çŸ©é˜µ"""
        # å°†å‚æ•°é‡å¡‘ä¸ºçŸ©é˜µ
        param_matrix = params.view(self.dim, self.dim)

        # æ„é€ åå„ç±³çŸ©é˜µ: A = (M - Mâ€ ) / 2 + i * (M + Mâ€ ) / 2
        real_part = (param_matrix - param_matrix.T) / 2
        imag_part = (param_matrix + param_matrix.T) / 2

        antihermitian = real_part + 1j * imag_part
        return antihermitian

    def proper_unitary_dilation(self, U_small):
        """
        æ­£ç¡®çš„é…‰æ‰©å¼ æ–¹æ³•ï¼Œå°† NÃ—N çš„ U_small åµŒå…¥æˆä¸€ä¸ª 2NÃ—2N çš„é…‰çŸ©é˜µ U_dilationã€‚

        æ‰©å¼ ç»“æ„ä¸ºï¼š
            U_dilation = [ U,              I - Uâ€ U      ]
                         [ I - UUâ€ ,        -Uâ€           ]
        """
        device = U_small.device  # è·å–å¼ é‡æ‰€åœ¨è®¾å¤‡ï¼ˆGPU æˆ– CPUï¼‰
        n = U_small.shape[0]  # è·å–è¾“å…¥çŸ©é˜µçš„ç»´åº¦ N

        # ============================================
        # âœ… ç¬¬ä¸€æ­¥ï¼šè®¡ç®— sqrt(I - Uâ€ U)
        # ============================================

        UH_U = torch.conj(U_small).T @ U_small  # è®¡ç®— Uâ€ U
        I = torch.eye(n, dtype=torch.cfloat, device=device)  # æ„é€ å•ä½é˜µ I

        complement = I - UH_U  # è®¡ç®—è¡¥ç©ºé—´ï¼šI - Uâ€ U

        # ç”±äºæ•°å€¼è¯¯å·®ï¼Œå¼ºåˆ¶å¯¹ç§°ï¼ˆå„ç±³ï¼‰åŒ–ä»¥ä¾¿è¿›è¡Œç‰¹å¾å€¼åˆ†è§£
        complement = (complement + torch.conj(complement).T) / 2

        # ============================================
        # âœ… ç¬¬äºŒæ­¥ï¼šè®¡ç®— sqrt(I - UUâ€ )
        # ============================================

        UU_H = U_small @ torch.conj(U_small).T  # è®¡ç®— UUâ€ 
        complement2 = I - UU_H  # è®¡ç®— I - UUâ€ 

        # åŒæ ·å¯¹ç§°åŒ–ä»¥ä¿è¯å„ç±³æ€§
        complement2 = (complement2 + torch.conj(complement2).T) / 2

        # ============================================
        # âœ… ç¬¬ä¸‰æ­¥ï¼šç»„è£…æœ€ç»ˆ 2NÃ—2N é…‰æ‰©å¼ çŸ©é˜µ
        # ============================================

        top = torch.cat([U_small, complement], dim=1)  # ä¸ŠåŠå— [U, sqrt(I - Uâ€ U)]
        bottom = torch.cat([complement2, -torch.conj(U_small)], dim=1)  # ä¸‹åŠå— [sqrt(I - UUâ€ ), -Uâ€ ]

        U_dilation = torch.cat([top, bottom], dim=0)  # çºµå‘æ‹¼æ¥æˆå®Œæ•´çŸ©é˜µ

        return U_dilation


    def forward(self, x_real, x_imag, edge_index):
        """å‰å‘ä¼ æ’­ - ç®€æ´ç‰ˆé…‰æ‹“å±•æ¼”åŒ–"""
        device = edge_index.device

        # ç¼–ç å›¾
        graph_emb = self.encode_graph(edge_index)

        # ç”Ÿæˆé…‰çŸ©é˜µ
        params = self.antihermitian_predictor(graph_emb)
        A = self.construct_antihermitian_matrix(params, device) * 0.1
        U_small = torch.matrix_exp(A)

        # é…‰æ‹“å±•
        U_dilation = self.proper_unitary_dilation(U_small)

        # åº”ç”¨æ¼”åŒ–
        x_complex = torch.complex(x_real, x_imag)
        evolved = torch.matmul(x_complex, U_dilation.T[:x_complex.shape[1], :x_complex.shape[1]])

        return evolved.real, evolved.imag



class LightningQuantumMessagePassing(MessagePassing):
    def __init__(self, in_channels, out_channels,
                 evolution_strength=0.3, aggr='add', **kwargs):
        super().__init__(aggr=aggr, **kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.evolution_strength = evolution_strength

        # çº¿æ€§å±‚
        self.lin_real = nn.Linear(in_channels, out_channels, bias=False)
        self.lin_imag = nn.Linear(in_channels, out_channels, bias=False)

        # ç›¸ä½æ—‹è½¬å™¨
        self.phase_rotator = LightningComplexRotation(max_phase=math.pi / 4)

        # é…‰æ‰©å¼  - åŸºäºå›¾ç»“æ„
        self.unitary_dilation = UnitaryDilationOperator(out_channels, contraction_factor=0.7, hidden_dim=64)

        # å±€éƒ¨è¾¹è€¦åˆ (ç¨³å®šç‰ˆ)
        self.edge_mlp = nn.Sequential(
            nn.LayerNorm(2 * out_channels),
            nn.Linear(2 * out_channels, out_channels // 2),
            nn.ReLU(),
            nn.Linear(out_channels // 2, 1),
            nn.Sigmoid()
        )

        # æ®‹å·®
        if in_channels != out_channels:
            self.residual_real = nn.Linear(in_channels, out_channels, bias=False)
            self.residual_imag = nn.Linear(in_channels, out_channels, bias=False)
            self.residual_norm = nn.LayerNorm(out_channels)
        else:
            self.residual_real = None
            self.residual_imag = None
            self.residual_norm = None

        self.reset_parameters()

    def reset_parameters(self):
        gain = 0.5
        nn.init.xavier_uniform_(self.lin_real.weight, gain=gain)
        nn.init.xavier_uniform_(self.lin_imag.weight, gain=gain)
        if self.residual_real is not None:
            nn.init.xavier_uniform_(self.residual_real.weight, gain=gain)
            nn.init.xavier_uniform_(self.residual_imag.weight, gain=gain)

    def forward(self, x, edge_index, edge_weight=None):
        if x.is_complex():
            x_real, x_imag = x.real, x.imag
        else:
            x_real = x
            x_imag = torch.zeros_like(x_real)

        x_real = torch.nan_to_num(x_real, nan=0.0, posinf=10.0, neginf=-10.0)
        x_imag = torch.nan_to_num(x_imag, nan=0.0, posinf=10.0, neginf=-10.0)

        try:
            x_real = F.layer_norm(x_real, x_real.shape[-1:])
            x_imag = F.layer_norm(x_imag, x_imag.shape[-1:])
        except Exception as e:
            x_real = torch.clamp(x_real, -1.0, 1.0)
            x_imag = torch.clamp(x_imag, -1.0, 1.0)

        edge_index, edge_weight = add_self_loops(edge_index, edge_weight, num_nodes=x.size(0))

        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šå­˜å‚¨edge_indexå’ŒèŠ‚ç‚¹æ•°ä¾›messageå‡½æ•°ä½¿ç”¨
        self._current_edge_index = edge_index
        self._current_num_nodes = x.size(0)

        out_real, out_imag = self.propagate(
            edge_index,
            x_real=x_real, x_imag=x_imag,
            edge_weight=edge_weight
        )

        if torch.isnan(out_real).any() or torch.isnan(out_imag).any():
            print("âŒ propagate è¾“å‡ºå« NaN")
            raise ValueError("âŒ propagate è¾“å‡ºå« NaN")

        if self.residual_real is not None:
            residual_real = self.residual_real(x_real)
            residual_imag = self.residual_imag(x_imag)
            mag = torch.sqrt(residual_real ** 2 + residual_imag ** 2 + 1e-8)
            norm_mag = self.residual_norm(mag)
            ratio = norm_mag / (mag + 1e-8)
            residual_real = residual_real * ratio
            residual_imag = residual_imag * ratio
        else:
            residual_real, residual_imag = x_real, x_imag

        out_real = 0.5 * out_real + 0.5 * residual_real
        out_imag = 0.5 * out_imag + 0.5 * residual_imag

        if torch.isnan(out_real).any() or torch.isnan(out_imag).any():
            print("âŒ æœ€ç»ˆè¾“å‡ºå« NaN")
            raise ValueError("âŒ æœ€ç»ˆè¾“å‡ºå« NaN")

        return torch.complex(out_real, out_imag)

    def message(self, x_real_i, x_imag_i, x_real_j, x_imag_j, edge_weight, index):
        h_real_i = self.lin_real(x_real_i)
        h_imag_i = self.lin_imag(x_imag_i)
        h_real_j = self.lin_real(x_real_j)
        h_imag_j = self.lin_imag(x_imag_j)

        h_real_i = torch.nan_to_num(h_real_i, nan=0.0, posinf=1e4, neginf=-1e4)
        h_imag_i = torch.nan_to_num(h_imag_i, nan=0.0, posinf=1e4, neginf=-1e4)
        h_real_j = torch.nan_to_num(h_real_j, nan=0.0, posinf=1e4, neginf=-1e4)
        h_imag_j = torch.nan_to_num(h_imag_j, nan=0.0, posinf=1e4, neginf=-1e4)

        magnitude_i = torch.sqrt(h_real_i ** 2 + h_imag_i ** 2 + 1e-8)
        magnitude_j = torch.sqrt(h_real_j ** 2 + h_imag_j ** 2 + 1e-8)

        neighbor_features = torch.cat([magnitude_i, magnitude_j], dim=-1)
        neighbor_features = torch.nan_to_num(neighbor_features, nan=0.0, posinf=10.0, neginf=-10.0)
        neighbor_features = torch.clamp(neighbor_features, min=0.0, max=10.0)

        local_coupling = self.edge_mlp(neighbor_features).squeeze(-1)
        local_coupling = torch.nan_to_num(local_coupling, nan=0.5, posinf=1.0, neginf=0.0)

        if edge_weight is not None:
            edge_weight = torch.clamp(edge_weight, 0.1, 2.0)
            phase_angles = self.evolution_strength * local_coupling * edge_weight
        else:
            phase_angles = self.evolution_strength * local_coupling

        phase_angles = torch.nan_to_num(phase_angles, nan=0.0, posinf=math.pi / 4, neginf=-math.pi / 4)

        evolved_real, evolved_imag = self.phase_rotator(h_real_j, h_imag_j, phase_angles)

        try:
            final_real, final_imag = self.unitary_dilation(evolved_real, evolved_imag)
        except Exception as e:
            print("âŒ é…‰æ‰©å¼ å¤±è´¥:", str(e))
            final_real = torch.zeros_like(evolved_real)
            final_imag = torch.zeros_like(evolved_imag)

        final_real = torch.nan_to_num(final_real, nan=0.0, posinf=10.0, neginf=-10.0)
        final_imag = torch.nan_to_num(final_imag, nan=0.0, posinf=10.0, neginf=-10.0)

        return final_real, final_imag

    def aggregate(self, inputs, index, ptr=None, dim_size=None):
        real_part, imag_part = inputs
        aggr_real = super().aggregate(real_part, index, ptr=ptr, dim_size=dim_size)
        aggr_imag = super().aggregate(imag_part, index, ptr=ptr, dim_size=dim_size)
        aggr_real = torch.nan_to_num(aggr_real, nan=0.0, posinf=10.0, neginf=-10.0)
        aggr_imag = torch.nan_to_num(aggr_imag, nan=0.0, posinf=10.0, neginf=-10.0)
        return aggr_real, aggr_imag


# ==== æ•°å€¼ç¨³å®šçš„é‡å­GCNç½‘ç»œ ====
class LightningQuantumGCN(nn.Module):
    """
    ç»ˆææ€§èƒ½ä¼˜åŒ–çš„é‡å­GCN (æ•°å€¼ç¨³å®šç‰ˆ)
    ä¿æŒå®Œæ•´çš„: å¤æ•°æ¼”åŒ– + æ¨¡é•¿åˆ†ç±» + æ®‹å·®è¿æ¥ + å±€éƒ¨é…‰æ€§ + é…‰æ‹“å±•æ€§
    """

    def __init__(self, input_dim, hidden_dims, output_dim,
                 evolution_strengths=None, dropout=0.2):
        super().__init__()
        if input_dim > 128:
            self.reshape_flag = True
            self.reshape_linear = nn.Linear(input_dim, 128)
            dims = [128] + hidden_dims + [output_dim]
        else:
            self.reshape_flag = False
            dims = [input_dim] + hidden_dims + [output_dim]

        self.dropout = dropout

        # æ›´ä¿å®ˆçš„é»˜è®¤æ¼”åŒ–å¼ºåº¦
        if evolution_strengths is None:
            evolution_strengths = [0.2, 0.3, 0.25][:len(dims) - 1]
            evolution_strengths += [evolution_strengths[-1]] * (len(dims) - 1 - len(evolution_strengths))

        # æ„å»ºé—ªç”µçº§é‡å­å±‚
        self.quantum_layers = nn.ModuleList()
        for i in range(len(dims) - 1):
            layer = LightningQuantumMessagePassing(
                in_channels=dims[i],
                out_channels=dims[i + 1],
                evolution_strength=evolution_strengths[i]
            )
            self.quantum_layers.append(layer)

        # é«˜æ•ˆå¤æ•°æ‰¹å½’ä¸€åŒ–
        self.batch_norms = nn.ModuleList([
            NaiveComplexBatchNorm1d(dims[i + 1])
            for i in range(len(dims) - 1)
        ])

        # æ·»åŠ æ¢¯åº¦è£å‰ªé’©å­
        self.register_backward_hook(self._gradient_clipping_hook)

        print(f"ğŸš€ æ„å»ºæ•°å€¼ç¨³å®šçš„é—ªç”µçº§é‡å­GCN: {dims}")

    def _gradient_clipping_hook(self, module, grad_input, grad_output):
        """æ¢¯åº¦è£å‰ªé’©å­"""
        if grad_output[0] is not None:
            torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch

        if self.reshape_flag:
            x = self.reshape_linear(x)

        # é‡å­æ¼”åŒ–è¿‡ç¨‹
        for i, (quantum_layer, batch_norm) in enumerate(zip(self.quantum_layers, self.batch_norms)):
            # é‡å­æ¶ˆæ¯ä¼ é€’
            x = quantum_layer(x, edge_index)

            # æ£€æŸ¥ä¸­é—´ç»“æœ
            if torch.isnan(x).any() or torch.isinf(x).any():
                print(f"âŒ ç¬¬ {i} å±‚åè¾“å‡ºå‡ºç° NaN æˆ– Inf")
                raise ValueError("ä¸­é—´ç»“æœåŒ…å«éæ³•å€¼")

            # å¤æ•°æ‰¹å½’ä¸€åŒ–
            x = batch_norm(x)

            # å¤æ•°ReLUæ¿€æ´»
            x = complex_relu(x)

            # Dropout (é™¤æœ€åä¸€å±‚)
            if i < len(self.quantum_layers) - 1 and self.dropout > 0:
                x = complex_dropout(x, self.dropout, training=self.training)

        # æ¨¡é•¿åˆ†ç±» (ä¿æŒé‡å­æµ‹é‡è¯­ä¹‰)
        x = x.abs()  # æ¨¡é•¿æ“ä½œ |ÏˆâŸ© -> |âŸ¨Ïˆ|ÏˆâŸ©|

        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§
        x = torch.clamp(x, min=1e-8, max=100)

        # å…¨å±€å›¾çº§è¡¨ç¤º
        x = global_mean_pool(x, batch)

        # æœ€ç»ˆè¾“å‡ºå‰çš„ç¨³å®šæ€§æ£€æŸ¥
        if torch.isnan(x).any() or torch.isinf(x).any():
            print("è­¦å‘Š: æœ€ç»ˆè¾“å‡ºå‰åŒ…å«NaNæˆ–Infï¼Œè¿›è¡Œä¿®å¤")
            x = torch.where(torch.isnan(x) | torch.isinf(x), torch.ones_like(x) * 1e-8, x)

        return F.log_softmax(x, dim=1)


# ==== æ•°æ®åŠ è½½å’Œé¢„å¤„ç† ====
def load_and_preprocess_data(dataset_name="MUTAG", batch_size=64):
    """åŠ è½½å’Œé¢„å¤„ç†å›¾æ•°æ®é›†"""
    print(f"ğŸ“Š åŠ è½½æ•°æ®é›†: {dataset_name}")

    # åŠ è½½æ•°æ®é›†
    transform = Compose([
        ToUndirected(),
        NormalizeFeatures()
    ])

    try:
        dataset = TUDataset(root=f'/tmp/{dataset_name}', name=dataset_name, transform=transform)
    except:
        print(f"âŒ æ— æ³•åŠ è½½ {dataset_name}ï¼Œä½¿ç”¨åˆæˆæ•°æ®")
        return create_synthetic_dataset(batch_size)

    print(f"âœ… æ•°æ®é›†ä¿¡æ¯:")
    print(f"  - å›¾æ•°é‡: {len(dataset)}")
    print(f"  - ç‰¹å¾ç»´åº¦: {dataset.num_node_features}")
    print(f"  - ç±»åˆ«æ•°: {dataset.num_classes}")
    print(f"  - å¹³å‡èŠ‚ç‚¹æ•°: {np.mean([data.num_nodes for data in dataset]):.1f}")

    # åˆ’åˆ†æ•°æ®é›†
    train_size = int(0.8 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size, test_size]
    )

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader, test_loader, dataset.num_node_features, dataset.num_classes


def create_synthetic_dataset(batch_size=64):
    """åˆ›å»ºåˆæˆå›¾æ•°æ®é›†ç”¨äºæµ‹è¯•"""
    print("ğŸ”§ åˆ›å»ºåˆæˆæ•°æ®é›†")

    # ç”Ÿæˆåˆæˆå›¾æ•°æ®
    graphs = []
    num_graphs = 1000
    num_classes = 5

    for i in range(num_graphs):
        # éšæœºå›¾å¤§å°
        num_nodes = np.random.randint(10, 50)
        num_features = 16

        # åˆ›å»ºéšæœºå›¾
        edge_index = erdos_renyi_graph(num_nodes, edge_prob=0.15)
        x = torch.randn(num_nodes, num_features) * 0.5
        y = torch.randint(0, num_classes, (1,))

        data = Data(x=x, edge_index=edge_index, y=y)
        graphs.append(data)

    # åˆ’åˆ†æ•°æ®é›†
    train_size = int(0.8 * len(graphs))
    val_size = int(0.1 * len(graphs))
    test_size = len(graphs) - train_size - val_size

    train_graphs = graphs[:train_size]
    val_graphs = graphs[train_size:train_size + val_size]
    test_graphs = graphs[train_size + val_size:]

    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader, test_loader, num_features, num_classes


# ==== è®­ç»ƒå’Œè¯„ä¼°å‡½æ•° ====
def train_lightning_model(model, train_loader, val_loader, device, epochs=50):
    """è®­ç»ƒæ•°å€¼ç¨³å®šçš„é‡å­GCNæ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ•°å€¼ç¨³å®šçš„é‡å­GCN")

    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    criterion = nn.CrossEntropyLoss()

    train_losses = []
    val_accuracies = []

    best_val_acc = 0.0
    patience = 10
    patience_counter = 0

    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_loss = 0
        num_batches = 0
        nan_batches = 0

        for batch_idx, batch in enumerate(train_loader):
            batch = batch.to(device)

            try:
                optimizer.zero_grad()

                # å‰å‘ä¼ æ’­
                out = model(batch)

                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«NaN
                if torch.isnan(out).any() or torch.isinf(out).any():
                    print(f"âš ï¸ Epoch {epoch}, Batch {batch_idx}: è¾“å‡ºåŒ…å«NaN/Infï¼Œè·³è¿‡")
                    nan_batches += 1
                    continue

                loss = criterion(out, batch.y)

                # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºNaN
                if torch.isnan(loss).any():
                    print(f"âš ï¸ Epoch {epoch}, Batch {batch_idx}: æŸå¤±ä¸ºNaNï¼Œè·³è¿‡")
                    nan_batches += 1
                    continue

                # åå‘ä¼ æ’­
                loss.backward()

                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

                optimizer.step()

                total_loss += loss.item()
                num_batches += 1

            except Exception as e:
                print(f"âš ï¸ Epoch {epoch}, Batch {batch_idx}: è®­ç»ƒå¼‚å¸¸ {str(e)}")
                nan_batches += 1
                continue

        if num_batches == 0:
            print(f"âŒ Epoch {epoch}: æ‰€æœ‰æ‰¹æ¬¡éƒ½å¤±è´¥ï¼Œåœæ­¢è®­ç»ƒ")
            break

        avg_loss = total_loss / num_batches
        train_losses.append(avg_loss)

        # éªŒè¯é˜¶æ®µ
        val_acc = evaluate_model(model, val_loader, device)
        val_accuracies.append(val_acc)

        scheduler.step()

        # æ‰“å°è¿›åº¦
        if epoch % 5 == 0:
            print(f"Epoch {epoch:3d}: Loss={avg_loss:.4f}, Val_Acc={val_acc:.4f}, "
                  f"NaN_batches={nan_batches}/{len(train_loader)}, LR={scheduler.get_last_lr()[0]:.6f}")

        # æ—©åœæ£€æŸ¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            patience_counter = 0
        else:
            patience_counter += 1

        if patience_counter >= patience:
            print(f"ğŸ›‘ Early stopping at epoch {epoch}, best val acc: {best_val_acc:.4f}")
            break

    return train_losses, val_accuracies, best_val_acc


def evaluate_model(model, data_loader, device):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for batch in data_loader:
            batch = batch.to(device)

            try:
                out = model(batch)

                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«NaN
                if torch.isnan(out).any() or torch.isinf(out).any():
                    print("âš ï¸ è¯„ä¼°æ—¶å‘ç°NaN/Infè¾“å‡ºï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                    continue

                pred = out.argmax(dim=1)
                correct += (pred == batch.y).sum().item()
                total += batch.y.size(0)

            except Exception as e:
                print(f"âš ï¸ è¯„ä¼°å¼‚å¸¸: {str(e)}")
                continue

    return correct / total if total > 0 else 0.0


def detailed_model_analysis(model, test_loader, device):
    """è¯¦ç»†çš„æ¨¡å‹åˆ†æ"""
    print("\nğŸ” è¯¦ç»†æ¨¡å‹åˆ†æ")
    print("=" * 40)

    model.eval()
    all_preds = []
    all_labels = []
    layer_stats = []

    # æ³¨å†Œå‰å‘é’©å­æ¥æ”¶é›†å±‚ç»Ÿè®¡ä¿¡æ¯
    def hook_fn(module, input, output):
        if hasattr(output, 'abs'):  # å¤æ•°è¾“å‡º
            magnitude = output.abs()
            layer_stats.append({
                'mean_magnitude': magnitude.mean().item(),
                'std_magnitude': magnitude.std().item(),
                'max_magnitude': magnitude.max().item(),
                'has_nan': torch.isnan(magnitude).any().item(),
                'has_inf': torch.isinf(magnitude).any().item()
            })
        elif torch.is_tensor(output):  # å®æ•°è¾“å‡º
            layer_stats.append({
                'mean': output.mean().item(),
                'std': output.std().item(),
                'max': output.max().item(),
                'min': output.min().item(),
                'has_nan': torch.isnan(output).any().item(),
                'has_inf': torch.isinf(output).any().item()
            })

    # ä¸ºé‡å­å±‚æ³¨å†Œé’©å­
    handles = []
    for i, layer in enumerate(model.quantum_layers):
        handle = layer.register_forward_hook(hook_fn)
        handles.append(handle)

    with torch.no_grad():
        nan_count = 0
        total_samples = 0

        for batch_idx, batch in enumerate(test_loader):
            batch = batch.to(device)
            layer_stats.clear()  # æ¸…ç©ºç»Ÿè®¡ä¿¡æ¯

            try:
                out = model(batch)

                if torch.isnan(out).any() or torch.isinf(out).any():
                    nan_count += batch.y.size(0)
                    print(f"âš ï¸ Batch {batch_idx}: å‘ç°NaN/Infè¾“å‡º")
                else:
                    pred = out.argmax(dim=1)
                    all_preds.extend(pred.cpu().numpy())
                    all_labels.extend(batch.y.cpu().numpy())

                total_samples += batch.y.size(0)

                # æ‰“å°å±‚ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…å‰å‡ ä¸ªæ‰¹æ¬¡ï¼‰
                if batch_idx < 3:
                    print(f"\nBatch {batch_idx} å±‚ç»Ÿè®¡:")
                    for layer_idx, stats in enumerate(layer_stats):
                        print(f"  Layer {layer_idx}: {stats}")

            except Exception as e:
                print(f"âš ï¸ Batch {batch_idx} åˆ†æå¼‚å¸¸: {str(e)}")
                nan_count += batch.y.size(0)

    # ç§»é™¤é’©å­
    for handle in handles:
        handle.remove()

    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    if len(all_preds) > 0:
        accuracy = accuracy_score(all_labels, all_preds)
        print(f"\nğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœ:")
        print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"  æ•°å€¼ç¨³å®šæ€§: {(total_samples - nan_count) / total_samples * 100:.1f}%")
        print(f"  æˆåŠŸæ ·æœ¬: {len(all_preds)}/{total_samples}")

        # åˆ†ç±»æŠ¥å‘Šï¼ˆå¦‚æœç±»åˆ«ä¸å¤ªå¤šï¼‰
        if len(set(all_labels)) <= 10:
            print("\nåˆ†ç±»æŠ¥å‘Š:")
            print(classification_report(all_labels, all_preds))
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸé¢„æµ‹çš„æ ·æœ¬")

    return len(all_preds) / total_samples if total_samples > 0 else 0.0


def comprehensive_quantum_test():
    """ç»¼åˆé‡å­ç‰¹æ€§æµ‹è¯•"""
    print("\nğŸ§ª ç»¼åˆé‡å­ç‰¹æ€§æµ‹è¯•")
    print("=" * 50)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"è®¾å¤‡: {device}")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    num_nodes = 50
    num_features = 32
    edge_index = erdos_renyi_graph(num_nodes, edge_prob=0.1).to(device)
    x = torch.randn(num_nodes, num_features, device=device) * 0.01
    batch = torch.zeros(num_nodes, dtype=torch.long, device=device)
    data = Data(x=x, edge_index=edge_index, batch=batch)

    # åˆ›å»ºæ¨¡å‹
    model = LightningQuantumGCN(
        input_dim=num_features,
        hidden_dims=[64, 32, 16],
        output_dim=8,
        evolution_strengths=[0.15, 0.2, 0.25],
        dropout=0.1
    ).to(device)

    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # æµ‹è¯•1: åŸºæœ¬å‰å‘ä¼ æ’­
    print("\n1ï¸âƒ£ åŸºæœ¬å‰å‘ä¼ æ’­æµ‹è¯•")
    model.eval()
    try:
        with torch.no_grad():
            output = model(data)
            print(f"  âœ… è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"  âœ… è¾“å‡ºç±»å‹: {output.dtype}")
            print(f"  âœ… æ•°å€¼èŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
            print(f"  âœ… æ¦‚ç‡å’Œ: {torch.exp(output).sum():.4f}")

            has_nan = torch.isnan(output).any()
            has_inf = torch.isinf(output).any()
            print(f"  âœ… æ•°å€¼ç¨³å®š: NaN={has_nan}, Inf={has_inf}")

    except Exception as e:
        print(f"  âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False

    # æµ‹è¯•2: å¤æ•°æ¼”åŒ–ç‰¹æ€§
    print("\n2ï¸âƒ£ å¤æ•°æ¼”åŒ–ç‰¹æ€§æµ‹è¯•")
    try:
        layer = model.quantum_layers[0]
        x_complex = torch.complex(x, torch.zeros_like(x))

        with torch.no_grad():
            evolved = layer(x_complex, edge_index)

            print(f"  âœ… å¤æ•°è¾“å‡ºç±»å‹: {evolved.dtype}")
            print(f"  âœ… å¤æ•°å¹…åº¦èŒƒå›´: [{evolved.abs().min():.4f}, {evolved.abs().max():.4f}]")

            # æ£€æŸ¥æ¨¡é•¿ä¿æŒ
            input_norms = torch.norm(x_complex, dim=1)
            output_norms = torch.norm(evolved, dim=1)
            norm_diff = torch.abs(output_norms - input_norms).mean()
            print(f"  âœ… æ¨¡é•¿ä¿æŒè¯¯å·®: {norm_diff:.6f}")

    except Exception as e:
        print(f"  âŒ å¤æ•°æ¼”åŒ–æµ‹è¯•å¤±è´¥: {e}")

    # æµ‹è¯•3: é…‰æ‰©å¼ ç‰¹æ€§
    print("\n3ï¸âƒ£ é…‰æ‰©å¼ ç‰¹æ€§æµ‹è¯•")
    try:
        dilation_op = model.quantum_layers[0].unitary_dilation
        test_real = torch.randn(10, 64, device=device) * 0.01
        test_imag = torch.randn(10, 64, device=device) * 0.01

        with torch.no_grad():
            out_real, out_imag = dilation_op(test_real, test_imag, edge_index)

            input_energy = torch.sum(test_real ** 2 + test_imag ** 2)
            output_energy = torch.sum(out_real ** 2 + out_imag ** 2)
            energy_ratio = output_energy / input_energy

            print(f"  âœ… èƒ½é‡æ¯”ä¾‹: {energy_ratio:.4f} (ç†æƒ³å€¼â‰ˆ1.0)")
            print(f"  âœ… è¾“å‡ºæ— NaN: {not torch.isnan(out_real).any()}")

    except Exception as e:
        print(f"  âŒ é…‰æ‰©å¼ æµ‹è¯•å¤±è´¥: {e}")

    # æµ‹è¯•4: æ¢¯åº¦ç¨³å®šæ€§
    print("\n4ï¸âƒ£ æ¢¯åº¦ç¨³å®šæ€§æµ‹è¯•")
    try:
        model.train()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()

        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
        target = torch.randint(0, 8, (1,), device=device)

        for step in range(5):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()

            # æ£€æŸ¥æ¢¯åº¦
            total_norm = 0
            for p in model.parameters():
                if p.grad is not None:
                    param_norm = p.grad.data.norm(2)
                    total_norm += param_norm.item() ** 2
            total_norm = total_norm ** (1. / 2)

            optimizer.step()

            print(f"  Step {step}: Loss={loss.item():.4f}, Grad_norm={total_norm:.4f}")

            if torch.isnan(loss) or total_norm > 100:
                print(f"  âŒ æ¢¯åº¦ä¸ç¨³å®š")
                break
        else:
            print(f"  âœ… æ¢¯åº¦ç¨³å®š")

    except Exception as e:
        print(f"  âŒ æ¢¯åº¦æµ‹è¯•å¤±è´¥: {e}")

    print("\nğŸ‰ ç»¼åˆé‡å­ç‰¹æ€§æµ‹è¯•å®Œæˆ")
    return True


def full_pipeline_test():
    """å®Œæ•´æµæ°´çº¿æµ‹è¯•"""
    print("\nğŸš€ å®Œæ•´æµæ°´çº¿æµ‹è¯•")
    print("=" * 50)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    try:
        # 1. æ•°æ®åŠ è½½
        print("1ï¸âƒ£ åŠ è½½æ•°æ®...")
        train_loader, val_loader, test_loader, num_features, num_classes = load_and_preprocess_data(
            dataset_name="MUTAG", batch_size=32
        )

        # 2. æ¨¡å‹åˆ›å»º
        print("2ï¸âƒ£ åˆ›å»ºæ¨¡å‹...")
        model = LightningQuantumGCN(
            input_dim=num_features,
            hidden_dims=[64, 32],
            output_dim=num_classes,
            evolution_strengths=[0.2, 0.3],
            dropout=0.1
        ).to(device)

        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

        # 3. è®­ç»ƒ
        print("3ï¸âƒ£ å¼€å§‹è®­ç»ƒ...")
        train_losses, val_accuracies, best_val_acc = train_lightning_model(
            model, train_loader, val_loader, device, epochs=20
        )

        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")

        # 4. æµ‹è¯•
        print("4ï¸âƒ£ æœ€ç»ˆæµ‹è¯•...")
        test_acc = evaluate_model(model, test_loader, device)
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")

        # 5. è¯¦ç»†åˆ†æ
        success_rate = detailed_model_analysis(model, test_loader, device)

        # 6. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if len(train_losses) > 0 and len(val_accuracies) > 0:
            plt.figure(figsize=(12, 4))

            plt.subplot(1, 2, 1)
            plt.plot(train_losses)
            plt.title('Training Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.grid(True)

            plt.subplot(1, 2, 2)
            plt.plot(val_accuracies)
            plt.title('Validation Accuracy')
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.grid(True)

            plt.tight_layout()
            plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')
            plt.show()
            print("ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜ä¸º training_curves.png")

        print(f"\nğŸ¯ æœ€ç»ˆç»“æœæ€»ç»“:")
        print(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
        print(f"  æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        print(f"  æ•°å€¼ç¨³å®šæ€§: {success_rate * 100:.1f}%")

        return test_acc > 0.5 and success_rate > 0.8

    except Exception as e:
        print(f"âŒ å®Œæ•´æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}")
        return False


# ==== å¸¦æ•°å€¼ç¨³å®šæ€§ç›‘æ§çš„æ€§èƒ½åŸºå‡†æµ‹è¯• ====
def lightning_benchmark():
    """é—ªç”µçº§æ€§èƒ½æµ‹è¯• (æ•°å€¼ç¨³å®šç‰ˆ)"""
    print("âš¡ æ•°å€¼ç¨³å®šçš„é—ªç”µçº§é‡å­GCNæ€§èƒ½æµ‹è¯•")
    print("=" * 50)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"è®¾å¤‡: {device}")

    # æµ‹è¯•é…ç½® - é€‚ä¸­è§„æ¨¡
    configs = [
        {"nodes": 200, "features": 32, "name": "å°å›¾"},
        {"nodes": 500, "features": 64, "name": "ä¸­ç­‰å›¾"},
        {"nodes": 1000, "features": 128, "name": "å¤§å›¾"},
        {"nodes": 10, "features": 1323, "name": "ç‰¹å¾å¤§å›¾"},
    ]

    for config in configs:
        print(f"\nğŸ”¥ {config['name']}: {config['nodes']} èŠ‚ç‚¹, {config['features']} ç‰¹å¾")

        # æ„å»ºæµ‹è¯•æ•°æ® - æ›´ä¿å®ˆçš„åˆå§‹åŒ–
        num_nodes = config['nodes']
        num_features = config['features']
        edge_index = erdos_renyi_graph(num_nodes, edge_prob=0.02).to(device)
        x = torch.randn(num_nodes, num_features, device=device) * 0.01  # æ›´å°çš„åˆå§‹åŒ–
        batch = torch.zeros(num_nodes, dtype=torch.long, device=device)
        data = Data(x=x, edge_index=edge_index, batch=batch)

        # æ•°å€¼ç¨³å®šçš„æ¨¡å‹
        model = LightningQuantumGCN(
            input_dim=num_features,
            hidden_dims=[64, 32],
            output_dim=10,
            evolution_strengths=[0.2, 0.3, 0.25],
            dropout=0.2
        ).to(device)

        print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")

        # æ€§èƒ½æµ‹è¯•
        model.eval()
        with torch.no_grad():

            # é¢„çƒ­GPU
            for _ in range(3):
                try:
                    _ = model(data)
                except:
                    print("é¢„çƒ­è¿‡ç¨‹ä¸­å‘ç°æ•°å€¼é—®é¢˜ï¼Œè·³è¿‡æ­¤é…ç½®")
                    break

            # åŒæ­¥å¹¶å¼€å§‹è®¡æ—¶
            if device.type == 'cuda':
                torch.cuda.synchronize()

            start_time = time.time()
            nan_count = 0

            # æ‰¹é‡æµ‹è¯•
            for i in range(10):
                try:
                    output = model(data)
                    if torch.isnan(output).any() or torch.isinf(output).any():
                        nan_count += 1
                except:
                    nan_count += 1

            if device.type == 'cuda':
                torch.cuda.synchronize()

            end_time = time.time()

            avg_time = (end_time - start_time) / 10 * 1000  # ms
            print(f"  âš¡ å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
            print(f"  ğŸ“Š ååé‡: {1000 / avg_time:.1f} graphs/sec")
            print(f"  âš ï¸ æ•°å€¼å¼‚å¸¸æ¬¡æ•°: {nan_count}/10")

            # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
            if nan_count == 0:
                print(f"  âœ… è¾“å‡ºç¨³å®šæ€§: å®Œå…¨ç¨³å®š")
                print(f"  ğŸ¯ è¾“å‡ºæ¦‚ç‡å’Œ: {torch.exp(output).sum(dim=1).mean().item():.4f}")
            else:
                print(f"  âŒ è¾“å‡ºç¨³å®šæ€§: æ£€æµ‹åˆ°{nan_count}æ¬¡æ•°å€¼å¼‚å¸¸")

        # GPUå†…å­˜ä½¿ç”¨
        if device.type == 'cuda':
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()

            with torch.no_grad():
                try:
                    _ = model(data)
                    peak_memory = torch.cuda.max_memory_allocated() / 1024 ** 2
                    print(f"  ğŸ’¾ å³°å€¼GPUå†…å­˜: {peak_memory:.1f} MB")
                except:
                    print("  ğŸ’¾ å†…å­˜æµ‹è¯•å¤±è´¥")


def test_quantum_properties_lightning():
    """éªŒè¯æ‰€æœ‰é‡å­ç‰¹æ€§ä¿æŒ (æ•°å€¼ç¨³å®šç‰ˆ)"""
    print("\nğŸ§ª é‡å­ç‰¹æ€§å®Œæ•´æ€§éªŒè¯ (æ•°å€¼ç¨³å®šç‰ˆ)")
    print("=" * 40)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # æ„å»ºæµ‹è¯•å›¾ - ä¿å®ˆå‚æ•°
    num_nodes = 30
    num_features = 16
    edge_index = erdos_renyi_graph(num_nodes, edge_prob=0.1).to(device)
    x = torch.randn(num_nodes, num_features, device=device) * 0.01
    batch = torch.zeros(num_nodes, dtype=torch.long, device=device)
    data = Data(x=x, edge_index=edge_index, batch=batch)

    model = LightningQuantumGCN(
        input_dim=num_features,
        hidden_dims=[16, 8],
        output_dim=5,
        evolution_strengths=[0.2, 0.3, 0.25],
        dropout=0.0
    ).to(device)

    model.eval()
    with torch.no_grad():
        try:
            # 1. å¤æ•°æ¼”åŒ–æµ‹è¯•
            x_complex = torch.complex(x, torch.zeros_like(x))
            layer_out = model.quantum_layers[0](x_complex, edge_index)
            print(f"âœ… å¤æ•°æ¼”åŒ–: è¾“å‡ºç±»å‹ {layer_out.dtype}")
            print(f"âœ… å¤æ•°å¹…åº¦: mean={layer_out.abs().mean():.4f}, std={layer_out.abs().std():.4f}")

            # 2. é…‰æ€§éªŒè¯ (è¿‘ä¼¼)
            input_norm = torch.norm(x_complex, dim=1)
            output_norm = torch.norm(layer_out, dim=1)
            norm_preservation = torch.mean(torch.abs(output_norm - input_norm)).item()
            print(f"âœ… è¿‘ä¼¼é…‰æ€§: æ¨¡é•¿ä¿æŒè¯¯å·® {norm_preservation:.6f}")

            # 3. æ¨¡é•¿åˆ†ç±»æµ‹è¯•
            final_output = model(data)
            print(f"âœ… æ¨¡é•¿åˆ†ç±»: æœ€ç»ˆè¾“å‡ºä¸ºå®æ•° {final_output.dtype}")
            print(f"âœ… æ¦‚ç‡å½’ä¸€åŒ–: exp(log_softmax)å’Œ â‰ˆ 1.0: {torch.exp(final_output).sum(dim=1).mean():.6f}")

            # 4. æ•°å€¼ç¨³å®šæ€§éªŒè¯
            has_nan = torch.isnan(final_output).any().item()
            has_inf = torch.isinf(final_output).any().item()
            print(f"âœ… æ•°å€¼ç¨³å®šæ€§: NaN={has_nan}, Inf={has_inf}")

            # 5. é…‰æ‰©å¼ ç‰¹æ€§
            dilation_op = model.quantum_layers[0].unitary_dilation
            test_real = torch.randn(5, 16, device=device) * 0.01
            test_imag = torch.randn(5, 16, device=device) * 0.01

            dilated_real, dilated_imag = dilation_op(test_real, test_imag, edge_index, num_nodes)
            input_energy = torch.sum(test_real ** 2 + test_imag ** 2)
            output_energy = torch.sum(dilated_real ** 2 + dilated_imag ** 2)
            energy_ratio = (output_energy / input_energy).item()
            print(f"âœ… é…‰æ‰©å¼ : èƒ½é‡æ¯”ä¾‹ {energy_ratio:.4f} (ç†æƒ³å€¼â‰ˆ1.0)")

            print("ğŸ‰ æ‰€æœ‰é‡å­ç‰¹æ€§éªŒè¯é€šè¿‡ï¼Œæ•°å€¼ç¨³å®šï¼")

        except Exception as e:
            print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç°é”™è¯¯: {e}")
            return False

    return True


if __name__ == "__main__":
    print("ğŸš€ æ•°å€¼ç¨³å®šçš„é—ªç”µçº§é‡å­GCN - å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("=" * 60)

    # æµ‹è¯•1: é‡å­ç‰¹æ€§éªŒè¯
    print("\n" + "=" * 20 + " é‡å­ç‰¹æ€§éªŒè¯ " + "=" * 20)
    quantum_test_passed = test_quantum_properties_lightning()

    if not quantum_test_passed:
        print("âŒ é‡å­ç‰¹æ€§éªŒè¯å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
        exit(1)

    # æµ‹è¯•2: ç»¼åˆé‡å­ç‰¹æ€§æµ‹è¯•
    print("\n" + "=" * 20 + " ç»¼åˆé‡å­ç‰¹æ€§æµ‹è¯• " + "=" * 20)
    comprehensive_test_passed = comprehensive_quantum_test()

    # æµ‹è¯•3: æ€§èƒ½åŸºå‡†æµ‹è¯•
    print("\n" + "=" * 20 + " æ€§èƒ½åŸºå‡†æµ‹è¯• " + "=" * 20)
    lightning_benchmark()

    # æµ‹è¯•4: å®Œæ•´æµæ°´çº¿æµ‹è¯•
    print("\n" + "=" * 20 + " å®Œæ•´æµæ°´çº¿æµ‹è¯• " + "=" * 20)
    pipeline_test_passed = full_pipeline_test()

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•æ€»ç»“:")
    print(f"  âœ… é‡å­ç‰¹æ€§éªŒè¯: {'é€šè¿‡' if quantum_test_passed else 'å¤±è´¥'}")
    print(f"  âœ… ç»¼åˆé‡å­æµ‹è¯•: {'é€šè¿‡' if comprehensive_test_passed else 'å¤±è´¥'}")
    print(f"  âœ… å®Œæ•´æµæ°´çº¿: {'é€šè¿‡' if pipeline_test_passed else 'å¤±è´¥'}")

    if quantum_test_passed and comprehensive_test_passed and pipeline_test_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°å€¼ç¨³å®šçš„é‡å­GCNå·¥ä½œæ­£å¸¸ï¼")

        print("\nâš¡ æ•°å€¼ç¨³å®šæ€§ä¼˜åŒ–æ€»ç»“:")
        print("  ğŸ”§ ç›¸ä½è§’åº¦é™åˆ¶ - é˜²æ­¢ä¸‰è§’å‡½æ•°ä¸ç¨³å®š")
        print("  ğŸ”§ æ¢¯åº¦è£å‰ª - é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸")
        print("  ğŸ”§ å‚æ•°èŒƒå›´çº¦æŸ - ç¡®ä¿æ•°å€¼ç¨³å®š")
        print("  ğŸ”§ å±‚å½’ä¸€åŒ– - ç¨³å®šä¸­é—´æ¿€æ´»")
        print("  ğŸ”§ ä¿å®ˆåˆå§‹åŒ– - é™ä½å‘æ•£é£é™©")
        print("  ğŸ”§ å¼‚å¸¸å€¼æ£€æµ‹ - è¿è¡Œæ—¶NaN/Infå¤„ç†")
        print("  âœ… å®Œæ•´å¤æ•°æ¼”åŒ– - ä¿æŒ")
        print("  âœ… æ¨¡é•¿åˆ†ç±» - ä¿æŒ")
        print("  âœ… æ®‹å·®è¿æ¥ - ä¿æŒ")
        print("  âœ… å±€éƒ¨é…‰æ€§ - ä¿æŒ")
        print("  âœ… é…‰æ‹“å±•æ€§ U=[G/Î», I-GGâ€ /Î»; I-GGâ€ /Î», -Gâ€ /Î»] - å®Œæ•´å®ç°")
        print("  ğŸ¯ ç›®æ ‡: å½»åº•æ¶ˆé™¤NaNé—®é¢˜ï¼Œä¿æŒé‡å­ç‰¹æ€§ï¼")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")